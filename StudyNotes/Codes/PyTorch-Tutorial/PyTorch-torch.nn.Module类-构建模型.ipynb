{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PyTorch-torch.nn.Module类-构建模型.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyMZvXXNME3dgNwTcht99GIp",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/veager/StudyNotes/blob/new/StudyNotes/Codes/PyTorch-Tutorial/PyTorch-torch.nn.Module%E7%B1%BB-%E6%9E%84%E5%BB%BA%E6%A8%A1%E5%9E%8B.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "PyTorch torch.nn.Module 类 构建模型\n",
        "\n",
        "参考资料：\n",
        "\n",
        "- GitHub：StudyNotes/Codes/PyTorch-Tutorial/PyTorch-torch.nn.Module类-构建模型.ipynb\n",
        "\n",
        "- 博客：PyTorch torch.nn.Module 类 构建模型，[地址](https://www.cnblogs.com/veager/articles/16305187.html)"
      ],
      "metadata": {
        "id": "gwaGEdPqEy-w"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 0 加载数据"
      ],
      "metadata": {
        "id": "UxdXJYwHIDML"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F"
      ],
      "metadata": {
        "id": "84wmVTGLFS7E"
      },
      "execution_count": 133,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 0.1 加载 Iris 数据集"
      ],
      "metadata": {
        "id": "C7i7XtmoISUG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_diabetes\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "data = load_diabetes()\n",
        "X = data.data\n",
        "Y = data.target\n",
        "\n",
        "# 将输入输出数据归一化到 [0, 1] 之间\n",
        "scaler_X = MinMaxScaler().fit(X)\n",
        "scaler_Y = MinMaxScaler().fit(np.expand_dims(Y, axis=1))\n",
        "\n",
        "Xs = scaler_X.transform(X)\n",
        "Ys = scaler_Y.transform(np.expand_dims(Y, axis=1))\n",
        "\n",
        "print(Xs.shape, Ys.shape)\n",
        "print(Xs[:5], Ys[:5])\n",
        "print(pd.DataFrame(Xs).describe(), pd.DataFrame(Ys).describe())\n",
        "\n",
        "# 将数据转换为 tensor 类型 \n",
        "Xs_tensor = torch.tensor(Xs, dtype=torch.float)\n",
        "Ys_tensor = torch.tensor(Ys, dtype=torch.float)"
      ],
      "metadata": {
        "id": "ugyTu1xpZ4vG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "47f3e274-5ece-4754-8f1b-3481a2b0e73b"
      },
      "execution_count": 134,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(442, 10) (442, 1)\n",
            "[[0.66666667 1.         0.58264463 0.54929577 0.29411765 0.25697211\n",
            "  0.20779221 0.28208745 0.56221737 0.43939394]\n",
            " [0.48333333 0.         0.14876033 0.35211268 0.42156863 0.30677291\n",
            "  0.62337662 0.14104372 0.22244301 0.16666667]\n",
            " [0.88333333 1.         0.51652893 0.43661972 0.28921569 0.25896414\n",
            "  0.24675325 0.28208745 0.49658437 0.40909091]\n",
            " [0.08333333 0.         0.30165289 0.30985915 0.49509804 0.44721116\n",
            "  0.23376623 0.42313117 0.57293604 0.46969697]\n",
            " [0.51666667 0.         0.20661157 0.54929577 0.46568627 0.41733068\n",
            "  0.38961039 0.28208745 0.36236911 0.33333333]] [[0.39252336]\n",
            " [0.15576324]\n",
            " [0.36137072]\n",
            " [0.56386293]\n",
            " [0.34267913]]\n",
            "                0           1           2           3           4           5  \\\n",
            "count  442.000000  442.000000  442.000000  442.000000  442.000000  442.000000   \n",
            "mean     0.491968    0.468326    0.346107    0.459818    0.451668    0.367725   \n",
            "std      0.218484    0.499561    0.182567    0.194806    0.169647    0.151460   \n",
            "min      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
            "25%      0.320833    0.000000    0.214876    0.309859    0.329657    0.271165   \n",
            "50%      0.516667    0.000000    0.318182    0.436620    0.436275    0.355578   \n",
            "75%      0.666667    1.000000    0.465909    0.605634    0.552696    0.462649   \n",
            "max      1.000000    1.000000    1.000000    1.000000    1.000000    1.000000   \n",
            "\n",
            "                6           7           8           9  \n",
            "count  442.000000  442.000000  442.000000  442.000000  \n",
            "mean     0.360889    0.291996    0.485557    0.503942  \n",
            "std      0.167977    0.182010    0.183364    0.174187  \n",
            "min      0.000000    0.000000    0.000000    0.000000  \n",
            "25%      0.237013    0.141044    0.357528    0.382576  \n",
            "50%      0.337662    0.282087    0.478057    0.500000  \n",
            "75%      0.464286    0.423131    0.610446    0.606061  \n",
            "max      1.000000    1.000000    1.000000    1.000000                   0\n",
            "count  442.000000\n",
            "mean     0.396054\n",
            "std      0.240165\n",
            "min      0.000000\n",
            "25%      0.193146\n",
            "50%      0.359813\n",
            "75%      0.580997\n",
            "max      1.000000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 0.2 全局参数设置"
      ],
      "metadata": {
        "id": "Xf0kFGsGKWna"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 样本信息，划分的数据集\n",
        "N_SAMPLE = Xs_tensor.size()[0]              # 样本总数\n",
        "N_TRAIN = int(N_SAMPLE * 0.7)               # 训练样本数\n",
        "N_VALID = int(N_SAMPLE * 0.2)               # 验证样本数\n",
        "N_TEST = N_SAMPLE - N_TRAIN - N_VALID       # 测试样本数\n",
        "\n",
        "\n",
        "# 训练过程超参数设置\n",
        "BATCH_SIZE = 64\n",
        "N_EPOCH = 1000\n",
        "LEARNING_RATE = 0.05\n",
        "\n",
        "\n",
        "# 神经网络模型参数\n",
        "HIDDEN_DIM = 4\n",
        "INPUT_DIM = Xs_tensor.size()[1]     # sizes of input data and output data\n",
        "OUTPUT_DIM = Ys_tensor.size()[1]\n",
        "print(\"NN Structure:\", INPUT_DIM, HIDDEN_DIM, OUTPUT_DIM)\n",
        "\n",
        "\n",
        "# 设置 device，如果 GPU 可用，则使用\n",
        "DEVICE = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "print(\"device:\", DEVICE)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R5U3xRjEKVxF",
        "outputId": "e3c5f311-1992-4a41-b078-07d04b784cba"
      },
      "execution_count": 135,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NN Structure: 10 4 1\n",
            "device: cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 0.3 创建结构化数据"
      ],
      "metadata": {
        "id": "FaMqo_x-Ioej"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import TensorDataset, Dataset, random_split, DataLoader\n",
        "from torch.utils.data.dataloader import default_collate\n",
        "\n",
        "# DataSet 类\n",
        "ds = TensorDataset(Xs_tensor, Ys_tensor)\n",
        "\n",
        "# split training, validation, testing data\n",
        "ds_train, ds_vaild, ds_test = random_split(ds, lengths=[N_TRAIN, N_VALID, N_TEST])\n",
        "print(len(ds_train), len(ds_vaild), len(ds_test))\n",
        "\n",
        "\n",
        "# DataLoader of train data, valid data, test data\n",
        "dl_train = DataLoader(ds_train, batch_size = BATCH_SIZE, shuffle = True,\n",
        "    collate_fn = lambda x: tuple(x_.to(DEVICE) for x_ in default_collate(x))\n",
        "    )\n",
        "\n",
        "dl_valid = DataLoader(ds_vaild, batch_size = BATCH_SIZE, # default shuffle = False,\n",
        "    collate_fn = lambda x: tuple(x_.to(DEVICE) for x_ in default_collate(x))\n",
        "    )\n",
        "\n",
        "dl_test = DataLoader(ds_test, batch_size = BATCH_SIZE, # default shuffle = False,\n",
        "    collate_fn = lambda x: tuple(x_.to(DEVICE) for x_ in default_collate(x))\n",
        "    )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3ngWqkICIYbz",
        "outputId": "32adc8e5-fadd-4ecc-8b3f-b9f4f9a18dc2"
      },
      "execution_count": 136,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "309 88 45\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 0.4 定义模型"
      ],
      "metadata": {
        "id": "z_BqissYIaGp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 方式 2: 全部使用 层类（nn.Module 类）\n",
        "class BPNNModeler2(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
        "\n",
        "        super(BPNNModeler2, self).__init__()\n",
        "\n",
        "        # Layer 1\n",
        "        self.layer1_linear = nn.Linear(input_dim, hidden_dim)\n",
        "        self.layer1_sigmoid = nn.Sigmoid()\n",
        "        # Layer 2\n",
        "        self.layer2_linear = nn.Linear(hidden_dim, output_dim)\n",
        "        self.layer2_sigmoid = nn.Sigmoid()\n",
        "        # Output\n",
        "        self.layer2_flattern = nn.Flatten(0, -1)\n",
        "    \n",
        "    # 正向传播\n",
        "    def forward(self, x):\n",
        "        # Layer 1\n",
        "        out_layer1 = self.layer1_linear(x)\n",
        "        out_layer1 = self.layer1_sigmoid(out_layer1)\n",
        "        # Layer 2\n",
        "        out_layer2 = self.layer2_linear(out_layer1)\n",
        "        out_layer2 = self.layer2_sigmoid(out_layer2)\n",
        "        # Output\n",
        "        out = self.layer2_flattern(out_layer2)\n",
        "        return out\n",
        "# =============================================================================="
      ],
      "metadata": {
        "id": "3AiyB78lIXa2"
      },
      "execution_count": 137,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 0.4.1 初始化模型"
      ],
      "metadata": {
        "id": "qfQ_PEy3LYoM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 定义模型\n",
        "model = BPNNModeler2(input_dim = INPUT_DIM, hidden_dim = HIDDEN_DIM, output_dim = OUTPUT_DIM)\n",
        "model = model.to(DEVICE)"
      ],
      "metadata": {
        "id": "0xniWxzQKikG"
      },
      "execution_count": 138,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 0.5 定义损失函数"
      ],
      "metadata": {
        "id": "kOBsRGv-I2wv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 定义 损失函数 MSE 损失\n",
        "def loss_func(model_out, target, reduction='mean'):\n",
        "    loss = F.mse_loss(model_out, target, reduction=reduction) \n",
        "    return loss"
      ],
      "metadata": {
        "id": "_mf3sHJ3I1C7"
      },
      "execution_count": 139,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1 基本框架"
      ],
      "metadata": {
        "id": "-p1IkD9lJBGh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MyModel(torch.nn.Module):\n",
        "    def __init__(self, params):\n",
        "        # params 传入模型的参数\n",
        "        super(MyModel, self).__init__()\n",
        "\t# 放入需要学习的参数，一般由 nn.Layer() 或 nn.Parameter() 定义\n",
        "    \n",
        "    # 正向传播\n",
        "    def forward(self, x):\n",
        "        # x: 为传入的数据，第1个维度（x.size()[0]）为 batch size\n",
        "        # 根据定义的参数，确定数据的传入顺序，构建模型\n",
        "        return out\n",
        "    \n",
        "    # 损失函数\n",
        "    def loss_func(self, out, target):\n",
        "        # out：模型的输出，一般为预测值\n",
        "        # target: 输出所对应的真实值\n",
        "        return loss\n",
        "    \n",
        "    # 预测类别，用于分类模型\n",
        "    def pred_label(self, prob):\n",
        "        # 分类模型的 out 通常为 [0,1] 之间的概率形式，通过 torch.argmax() 函数也获取概率最大的标签\n",
        "        label = torch.argmax(prob, dim, keepdim=False)\n",
        "        return label"
      ],
      "metadata": {
        "id": "t5TP1MajJMwI"
      },
      "execution_count": 140,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2 方法"
      ],
      "metadata": {
        "id": "LzjMFWRPJN4m"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.1 `torch.nn.Module()` 类主要方法"
      ],
      "metadata": {
        "id": "Q-JWvAIvJTcJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.2 `.zero_grad()` 方法使用"
      ],
      "metadata": {
        "id": "8titi_onJYsH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**实例 1**： 使用 `optimizer.zero_grad()`"
      ],
      "metadata": {
        "id": "7QYjXc8gJjBP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "N_EPOCH = 50\n",
        "LEARNING_RATE = 0.1\n",
        "\n",
        "# 定义优化器，模型参数 model.parameters() 传入到优化器中\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=LEARNING_RATE)  # model: 已定义的模型\n",
        "\n",
        "for epoch in range(N_EPOCH):\n",
        "\n",
        "    train_total_loss = 0.\n",
        "\n",
        "    for i, (X_batch, Y_batch) in enumerate(dl_train):    # dl_train: 已定义的 DataLoader 类\n",
        "        optimizer.zero_grad()    # 优化器中的模型参数的梯度归零\n",
        "\n",
        "        out = model(X_batch)                           \n",
        "        loss = loss_func(out, Y_batch.flatten())  \n",
        "        loss.backward()          # 反向传播，计算梯度\n",
        "        \n",
        "        optimizer.step()         # 执行一步优化，更新参数\n",
        "\n",
        "        train_total_loss += loss.item()\n",
        "\n",
        "    # Print Traing information\n",
        "    if (epoch + 1) % 1 == 0:\n",
        "        print('Epoch: {0:>4}, Train Loss: {1:>10.5f}'.format(epoch+1, train_total_loss))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S5kdXSldJTCT",
        "outputId": "6201ca89-a2ea-4fa3-af9f-d84a5ee0573a"
      },
      "execution_count": 141,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch:    1, Train Loss:    0.29705\n",
            "Epoch:    2, Train Loss:    0.29227\n",
            "Epoch:    3, Train Loss:    0.28697\n",
            "Epoch:    4, Train Loss:    0.28254\n",
            "Epoch:    5, Train Loss:    0.27993\n",
            "Epoch:    6, Train Loss:    0.27822\n",
            "Epoch:    7, Train Loss:    0.27408\n",
            "Epoch:    8, Train Loss:    0.27823\n",
            "Epoch:    9, Train Loss:    0.27557\n",
            "Epoch:   10, Train Loss:    0.27367\n",
            "Epoch:   11, Train Loss:    0.27255\n",
            "Epoch:   12, Train Loss:    0.27147\n",
            "Epoch:   13, Train Loss:    0.27297\n",
            "Epoch:   14, Train Loss:    0.27161\n",
            "Epoch:   15, Train Loss:    0.27282\n",
            "Epoch:   16, Train Loss:    0.27073\n",
            "Epoch:   17, Train Loss:    0.27212\n",
            "Epoch:   18, Train Loss:    0.26938\n",
            "Epoch:   19, Train Loss:    0.27095\n",
            "Epoch:   20, Train Loss:    0.27007\n",
            "Epoch:   21, Train Loss:    0.27129\n",
            "Epoch:   22, Train Loss:    0.27073\n",
            "Epoch:   23, Train Loss:    0.27133\n",
            "Epoch:   24, Train Loss:    0.27064\n",
            "Epoch:   25, Train Loss:    0.26877\n",
            "Epoch:   26, Train Loss:    0.27210\n",
            "Epoch:   27, Train Loss:    0.27430\n",
            "Epoch:   28, Train Loss:    0.26945\n",
            "Epoch:   29, Train Loss:    0.27067\n",
            "Epoch:   30, Train Loss:    0.26954\n",
            "Epoch:   31, Train Loss:    0.26981\n",
            "Epoch:   32, Train Loss:    0.27261\n",
            "Epoch:   33, Train Loss:    0.27058\n",
            "Epoch:   34, Train Loss:    0.27332\n",
            "Epoch:   35, Train Loss:    0.26936\n",
            "Epoch:   36, Train Loss:    0.26993\n",
            "Epoch:   37, Train Loss:    0.27162\n",
            "Epoch:   38, Train Loss:    0.26957\n",
            "Epoch:   39, Train Loss:    0.26893\n",
            "Epoch:   40, Train Loss:    0.27009\n",
            "Epoch:   41, Train Loss:    0.26837\n",
            "Epoch:   42, Train Loss:    0.26963\n",
            "Epoch:   43, Train Loss:    0.27084\n",
            "Epoch:   44, Train Loss:    0.27055\n",
            "Epoch:   45, Train Loss:    0.27056\n",
            "Epoch:   46, Train Loss:    0.26779\n",
            "Epoch:   47, Train Loss:    0.26983\n",
            "Epoch:   48, Train Loss:    0.27002\n",
            "Epoch:   49, Train Loss:    0.26988\n",
            "Epoch:   50, Train Loss:    0.26920\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**实例 2**： 使用 `model.zero_grad()`"
      ],
      "metadata": {
        "id": "bfojtkvnKDgh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "N_EPOCH = 50\n",
        "LEARNING_RATE = 0.5\n",
        "\n",
        "for epoch in range(N_EPOCH):\n",
        "\n",
        "    train_total_loss = 0.\n",
        "\n",
        "    for i, (X_batch, Y_batch) in enumerate(dl_train):   # dl_train: 已定义的 DataLoader 类\n",
        "        model.zero_grad()       # 模型参数参数梯度归零    # model: 已定义的模型\n",
        "\n",
        "        out = model(X_batch)                           \n",
        "        loss = loss_func(out, Y_batch.flatten())  \n",
        "        loss.backward()         # 反向传播，计算梯度\n",
        "\n",
        "        with torch.no_grad():   # 更新参数时，要取消梯度追踪\n",
        "            for param in model.parameters():\n",
        "                param -= LEARNING_RATE * param.grad     # 更新参数\n",
        "\n",
        "        train_total_loss += loss.item()\n",
        "\n",
        "    # Print Traing information\n",
        "    if (epoch + 1) % 1 == 0:\n",
        "        print('Epoch: {0:>4}, Train Loss: {1:>10.5f}'.format(epoch+1, train_total_loss))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uVkuQk2bJNdu",
        "outputId": "86f5804c-e75c-469f-ce24-c42578507607"
      },
      "execution_count": 142,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch:    1, Train Loss:    0.27283\n",
            "Epoch:    2, Train Loss:    0.27049\n",
            "Epoch:    3, Train Loss:    0.26930\n",
            "Epoch:    4, Train Loss:    0.26897\n",
            "Epoch:    5, Train Loss:    0.26955\n",
            "Epoch:    6, Train Loss:    0.27157\n",
            "Epoch:    7, Train Loss:    0.27048\n",
            "Epoch:    8, Train Loss:    0.27038\n",
            "Epoch:    9, Train Loss:    0.27048\n",
            "Epoch:   10, Train Loss:    0.26702\n",
            "Epoch:   11, Train Loss:    0.27042\n",
            "Epoch:   12, Train Loss:    0.26783\n",
            "Epoch:   13, Train Loss:    0.26668\n",
            "Epoch:   14, Train Loss:    0.27007\n",
            "Epoch:   15, Train Loss:    0.26883\n",
            "Epoch:   16, Train Loss:    0.26788\n",
            "Epoch:   17, Train Loss:    0.26620\n",
            "Epoch:   18, Train Loss:    0.26795\n",
            "Epoch:   19, Train Loss:    0.26472\n",
            "Epoch:   20, Train Loss:    0.26747\n",
            "Epoch:   21, Train Loss:    0.26902\n",
            "Epoch:   22, Train Loss:    0.26773\n",
            "Epoch:   23, Train Loss:    0.26717\n",
            "Epoch:   24, Train Loss:    0.26592\n",
            "Epoch:   25, Train Loss:    0.26475\n",
            "Epoch:   26, Train Loss:    0.26415\n",
            "Epoch:   27, Train Loss:    0.26629\n",
            "Epoch:   28, Train Loss:    0.26644\n",
            "Epoch:   29, Train Loss:    0.26703\n",
            "Epoch:   30, Train Loss:    0.26480\n",
            "Epoch:   31, Train Loss:    0.26484\n",
            "Epoch:   32, Train Loss:    0.26731\n",
            "Epoch:   33, Train Loss:    0.26284\n",
            "Epoch:   34, Train Loss:    0.26715\n",
            "Epoch:   35, Train Loss:    0.26379\n",
            "Epoch:   36, Train Loss:    0.26251\n",
            "Epoch:   37, Train Loss:    0.26076\n",
            "Epoch:   38, Train Loss:    0.26269\n",
            "Epoch:   39, Train Loss:    0.26047\n",
            "Epoch:   40, Train Loss:    0.26390\n",
            "Epoch:   41, Train Loss:    0.26241\n",
            "Epoch:   42, Train Loss:    0.26135\n",
            "Epoch:   43, Train Loss:    0.26216\n",
            "Epoch:   44, Train Loss:    0.26644\n",
            "Epoch:   45, Train Loss:    0.26389\n",
            "Epoch:   46, Train Loss:    0.26074\n",
            "Epoch:   47, Train Loss:    0.26076\n",
            "Epoch:   48, Train Loss:    0.25852\n",
            "Epoch:   49, Train Loss:    0.25842\n",
            "Epoch:   50, Train Loss:    0.25993\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.3 训练模式和评估模型"
      ],
      "metadata": {
        "id": "u4hg7VfhMP5h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "N_EPOCH = 50\n",
        "LEARNING_RATE = 0.1\n",
        "\n",
        "# 定义优化器\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=LEARNING_RATE)\n",
        "\n",
        "# 模型训练过程\n",
        "for epoch in range(N_EPOCH):\n",
        "    # 模型训练\n",
        "    train_total_loss = 0.\n",
        "\n",
        "    model.train()    # 启动模型训练模式\n",
        "    for i, (X_batch, Y_batch) in enumerate(dl_train):\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        out = model(X_batch)\n",
        "        loss = loss_func(out, Y_batch.flatten())\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        train_total_loss += loss.item()\n",
        "    \n",
        "\n",
        "    # 评估验证集 方式 1: 使用 torch.no_grad()\n",
        "    vaild_total_loss = 0.\n",
        "    \n",
        "    model.eval()    # 启动模型评估模式\n",
        "    with torch.no_grad():\n",
        "        for X_valid, Y_valid in dl_valid:\n",
        "            out = model(X_valid)\n",
        "            loss = loss_func(out, Y_valid.flatten())\n",
        "            vaild_total_loss += loss.item()\n",
        "\n",
        "\n",
        "    # 评估验证集 方式 2: 使用 .detach()\n",
        "    vaild_total_loss = 0.\n",
        "\n",
        "    model.eval()    # 启动模型评估模式\n",
        "    for X_valid, Y_valid in dl_valid:\n",
        "        # X_valid = X_valid.detach()  # 取消对 tensor 的梯度跟踪\n",
        "        # Y_valid = Y_valid.detach()\n",
        "        out = model(X_valid)\n",
        "\n",
        "        # print(X_valid.requires_grad, out.requires_grad)\n",
        "        # Output: False, True\n",
        "\n",
        "        out = out.detach() # 取消对 tensor 的梯度跟踪\n",
        "\n",
        "        loss = loss_func(out, Y_valid.flatten())\n",
        "        vaild_total_loss += loss.item()\n",
        "\n",
        "    if (epoch+1) % 1 == 0:\n",
        "        print(epoch + 1, ':', \n",
        "              round(train_total_loss, 5),\n",
        "              round(vaild_total_loss, 5))"
      ],
      "metadata": {
        "id": "7PKsqvrNcOWU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "353a4775-266c-454f-b59f-d8226ed33d8f"
      },
      "execution_count": 143,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1 : 0.25967 0.12118\n",
            "2 : 0.25907 0.12114\n",
            "3 : 0.25979 0.1211\n",
            "4 : 0.2586 0.12109\n",
            "5 : 0.25919 0.12105\n",
            "6 : 0.25855 0.12103\n",
            "7 : 0.25806 0.12101\n",
            "8 : 0.26 0.12098\n",
            "9 : 0.25814 0.12095\n",
            "10 : 0.25812 0.12093\n",
            "11 : 0.25848 0.12088\n",
            "12 : 0.25776 0.12087\n",
            "13 : 0.25812 0.12084\n",
            "14 : 0.25815 0.12082\n",
            "15 : 0.25751 0.12081\n",
            "16 : 0.26023 0.12076\n",
            "17 : 0.25758 0.12075\n",
            "18 : 0.25631 0.12072\n",
            "19 : 0.25734 0.12071\n",
            "20 : 0.25988 0.12067\n",
            "21 : 0.25908 0.12065\n",
            "22 : 0.25673 0.12064\n",
            "23 : 0.25508 0.1206\n",
            "24 : 0.25724 0.12057\n",
            "25 : 0.26094 0.12052\n",
            "26 : 0.25792 0.12048\n",
            "27 : 0.25501 0.12047\n",
            "28 : 0.25557 0.12043\n",
            "29 : 0.25573 0.12041\n",
            "30 : 0.2559 0.12041\n",
            "31 : 0.2557 0.12035\n",
            "32 : 0.25657 0.12032\n",
            "33 : 0.26006 0.12027\n",
            "34 : 0.25707 0.12023\n",
            "35 : 0.25698 0.12019\n",
            "36 : 0.25462 0.12015\n",
            "37 : 0.25483 0.12012\n",
            "38 : 0.25628 0.12009\n",
            "39 : 0.2559 0.12003\n",
            "40 : 0.25786 0.11999\n",
            "41 : 0.25477 0.11999\n",
            "42 : 0.25537 0.11997\n",
            "43 : 0.25659 0.11994\n",
            "44 : 0.2568 0.1199\n",
            "45 : 0.2551 0.11988\n",
            "46 : 0.25422 0.11985\n",
            "47 : 0.25541 0.11982\n",
            "48 : 0.25698 0.11976\n",
            "49 : 0.25589 0.11975\n",
            "50 : 0.25611 0.11972\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.4 GPU 部署相关"
      ],
      "metadata": {
        "id": "ldVn_DB2NVbO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.5 获取模型参数和模型结构"
      ],
      "metadata": {
        "id": "txrZQbXANYaI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.5.1 获取参数"
      ],
      "metadata": {
        "id": "Obh6DdpwNiXp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### A 遍历所有参数"
      ],
      "metadata": {
        "id": "Es5TnZhpNmOI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "layer_linear = nn.Linear(3, 5)\n",
        "\n",
        "print(\"---------.parameters() 方法-------------------\")\n",
        "for param in layer_linear.parameters():\n",
        "    print(type(param))\n",
        "    print(param.data.size())\n",
        "\n",
        "print(\"---------.named_parameters() 方法-------------\")\n",
        "for name, param in layer_linear.named_parameters():\n",
        "    print(type(param))\n",
        "    print(name, param.data.size())\n",
        "\n",
        "print(\"---------.state_dict() 方法-------------------\")\n",
        "for name, tensor in layer_linear.state_dict().items():\n",
        "    print(type(tensor))\n",
        "    print(name, tensor.size())\n",
        "\n",
        "print(\"---------.state_dict() 方法，遍历参数名--------\")\n",
        "for name in layer_linear.state_dict():\n",
        "    print(name)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cLggCJfuK6LS",
        "outputId": "79108384-a68e-49e9-da59-0556fa877678"
      },
      "execution_count": 144,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---------.parameters() 方法-------------------\n",
            "<class 'torch.nn.parameter.Parameter'>\n",
            "torch.Size([5, 3])\n",
            "<class 'torch.nn.parameter.Parameter'>\n",
            "torch.Size([5])\n",
            "---------.named_parameters() 方法-------------\n",
            "<class 'torch.nn.parameter.Parameter'>\n",
            "weight torch.Size([5, 3])\n",
            "<class 'torch.nn.parameter.Parameter'>\n",
            "bias torch.Size([5])\n",
            "---------.state_dict() 方法-------------------\n",
            "<class 'torch.Tensor'>\n",
            "weight torch.Size([5, 3])\n",
            "<class 'torch.Tensor'>\n",
            "bias torch.Size([5])\n",
            "---------.state_dict() 方法，遍历参数名--------\n",
            "weight\n",
            "bias\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "遍历无**学习参数**的 Module，输出为空"
      ],
      "metadata": {
        "id": "Zg7m8tQoOeIz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "layer_act = nn.Sigmoid()\n",
        "\n",
        "print(\"---------.parameters() 方法-------------------\")\n",
        "for param in layer_act.parameters():\n",
        "    print(param.data.size())\n",
        "\n",
        "print(\"---------.named_parameters() 方法-------------\")\n",
        "for name, param in layer_act.named_parameters():\n",
        "    print(name, param.data.size())\n",
        "\n",
        "print(\"---------.state_dict() 方法-------------------\")\n",
        "for name, tensor in layer_act.state_dict().items():\n",
        "    print(type(tensor))\n",
        "    print(name, tensor.size())\n",
        "\n",
        "print(\"---------.state_dict() 方法，遍历参数名--------\")\n",
        "for name in layer_act.state_dict():\n",
        "    print(name)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U1U3o1s8K3ex",
        "outputId": "19e140c3-889c-43fc-e27b-edcfeee3d97f"
      },
      "execution_count": 145,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---------.parameters() 方法-------------------\n",
            "---------.named_parameters() 方法-------------\n",
            "---------.state_dict() 方法-------------------\n",
            "---------.state_dict() 方法，遍历参数名--------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### B. 获取特定的学习参数"
      ],
      "metadata": {
        "id": "srSvTapgOWXn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(list(layer_linear.parameters())[0].detach())\n",
        "\n",
        "print(dict(layer_linear.named_parameters())['weight'].detach())\n",
        "\n",
        "print(layer_linear.state_dict()['weight'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k3195dGgO5iX",
        "outputId": "58e15fa8-419d-4d94-9890-e04e3f4df1b0"
      },
      "execution_count": 146,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 0.4041, -0.0876,  0.3021],\n",
            "        [-0.5672, -0.0522, -0.1677],\n",
            "        [-0.0101,  0.2798, -0.3804],\n",
            "        [-0.1652,  0.4419, -0.3795],\n",
            "        [ 0.1054, -0.4413, -0.0948]])\n",
            "tensor([[ 0.4041, -0.0876,  0.3021],\n",
            "        [-0.5672, -0.0522, -0.1677],\n",
            "        [-0.0101,  0.2798, -0.3804],\n",
            "        [-0.1652,  0.4419, -0.3795],\n",
            "        [ 0.1054, -0.4413, -0.0948]])\n",
            "tensor([[ 0.4041, -0.0876,  0.3021],\n",
            "        [-0.5672, -0.0522, -0.1677],\n",
            "        [-0.0101,  0.2798, -0.3804],\n",
            "        [-0.1652,  0.4419, -0.3795],\n",
            "        [ 0.1054, -0.4413, -0.0948]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.5.2 获取模块"
      ],
      "metadata": {
        "id": "RyXZmVj7O1am"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### A 遍历所有模块"
      ],
      "metadata": {
        "id": "2VW9b_HZOzBA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "contain_seq = nn.Sequential(\n",
        "    nn.Linear(3, 5), \n",
        "    nn.Sigmoid(), \n",
        "    nn.Sequential(\n",
        "        nn.Linear(5, 2), \n",
        "        nn.Sigmoid()\n",
        "    ))\n",
        "\n",
        "print(\"---------.parameters() 方法-------------------\")\n",
        "for param in contain_seq.parameters():\n",
        "    print(type(param))\n",
        "    print(param.data.size())\n",
        "\n",
        "print(\"---------.named_parameters() 方法-------------\")\n",
        "for name, param in contain_seq.named_parameters():\n",
        "    print(type(param))\n",
        "    print(name, param.data.size())\n",
        "\n",
        "print(\"---------.state_dict() 方法-------------------\")\n",
        "for name, tensor in contain_seq.state_dict().items():\n",
        "    print(type(tensor))\n",
        "    print(name, tensor.size())\n",
        "\n",
        "print(\"---------.modules() 方法----------------------\")\n",
        "# 获取模型中的 所有 模块\n",
        "for module in contain_seq.modules():\n",
        "    print(type(module))\n",
        "    print(module)\n",
        "\n",
        "print(\"---------.named_modules() 方法----------------\")\n",
        "# 获取模型中的 所有 模块名 和 模块\n",
        "for name, module in contain_seq.named_modules():\n",
        "    print(type(module))\n",
        "    print(name, module)\n",
        "\n",
        "print(\"---------.named_children() 方法----------------\")\n",
        "# 获取模型中的 直接 子模块名称 和 子模块\n",
        "for name, module in contain_seq.named_children():\n",
        "    print(type(module))\n",
        "    print(name, module)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SOCr2o78K5Oc",
        "outputId": "19c9a791-0811-4c3e-d093-02426af054af"
      },
      "execution_count": 147,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---------.parameters() 方法-------------------\n",
            "<class 'torch.nn.parameter.Parameter'>\n",
            "torch.Size([5, 3])\n",
            "<class 'torch.nn.parameter.Parameter'>\n",
            "torch.Size([5])\n",
            "<class 'torch.nn.parameter.Parameter'>\n",
            "torch.Size([2, 5])\n",
            "<class 'torch.nn.parameter.Parameter'>\n",
            "torch.Size([2])\n",
            "---------.named_parameters() 方法-------------\n",
            "<class 'torch.nn.parameter.Parameter'>\n",
            "0.weight torch.Size([5, 3])\n",
            "<class 'torch.nn.parameter.Parameter'>\n",
            "0.bias torch.Size([5])\n",
            "<class 'torch.nn.parameter.Parameter'>\n",
            "2.0.weight torch.Size([2, 5])\n",
            "<class 'torch.nn.parameter.Parameter'>\n",
            "2.0.bias torch.Size([2])\n",
            "---------.state_dict() 方法-------------------\n",
            "<class 'torch.Tensor'>\n",
            "0.weight torch.Size([5, 3])\n",
            "<class 'torch.Tensor'>\n",
            "0.bias torch.Size([5])\n",
            "<class 'torch.Tensor'>\n",
            "2.0.weight torch.Size([2, 5])\n",
            "<class 'torch.Tensor'>\n",
            "2.0.bias torch.Size([2])\n",
            "---------.modules() 方法----------------------\n",
            "<class 'torch.nn.modules.container.Sequential'>\n",
            "Sequential(\n",
            "  (0): Linear(in_features=3, out_features=5, bias=True)\n",
            "  (1): Sigmoid()\n",
            "  (2): Sequential(\n",
            "    (0): Linear(in_features=5, out_features=2, bias=True)\n",
            "    (1): Sigmoid()\n",
            "  )\n",
            ")\n",
            "<class 'torch.nn.modules.linear.Linear'>\n",
            "Linear(in_features=3, out_features=5, bias=True)\n",
            "<class 'torch.nn.modules.activation.Sigmoid'>\n",
            "Sigmoid()\n",
            "<class 'torch.nn.modules.container.Sequential'>\n",
            "Sequential(\n",
            "  (0): Linear(in_features=5, out_features=2, bias=True)\n",
            "  (1): Sigmoid()\n",
            ")\n",
            "<class 'torch.nn.modules.linear.Linear'>\n",
            "Linear(in_features=5, out_features=2, bias=True)\n",
            "<class 'torch.nn.modules.activation.Sigmoid'>\n",
            "Sigmoid()\n",
            "---------.named_modules() 方法----------------\n",
            "<class 'torch.nn.modules.container.Sequential'>\n",
            " Sequential(\n",
            "  (0): Linear(in_features=3, out_features=5, bias=True)\n",
            "  (1): Sigmoid()\n",
            "  (2): Sequential(\n",
            "    (0): Linear(in_features=5, out_features=2, bias=True)\n",
            "    (1): Sigmoid()\n",
            "  )\n",
            ")\n",
            "<class 'torch.nn.modules.linear.Linear'>\n",
            "0 Linear(in_features=3, out_features=5, bias=True)\n",
            "<class 'torch.nn.modules.activation.Sigmoid'>\n",
            "1 Sigmoid()\n",
            "<class 'torch.nn.modules.container.Sequential'>\n",
            "2 Sequential(\n",
            "  (0): Linear(in_features=5, out_features=2, bias=True)\n",
            "  (1): Sigmoid()\n",
            ")\n",
            "<class 'torch.nn.modules.linear.Linear'>\n",
            "2.0 Linear(in_features=5, out_features=2, bias=True)\n",
            "<class 'torch.nn.modules.activation.Sigmoid'>\n",
            "2.1 Sigmoid()\n",
            "---------.named_children() 方法----------------\n",
            "<class 'torch.nn.modules.linear.Linear'>\n",
            "0 Linear(in_features=3, out_features=5, bias=True)\n",
            "<class 'torch.nn.modules.activation.Sigmoid'>\n",
            "1 Sigmoid()\n",
            "<class 'torch.nn.modules.container.Sequential'>\n",
            "2 Sequential(\n",
            "  (0): Linear(in_features=5, out_features=2, bias=True)\n",
            "  (1): Sigmoid()\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### B. 获取指定的模块"
      ],
      "metadata": {
        "id": "63WtB77HPBIu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(list(contain_seq.modules())[0])\n",
        "\n",
        "print(dict(contain_seq.named_modules())['2.0'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sFMj9XumOrz9",
        "outputId": "20c09333-940b-4425-e0c9-80b7a81343d8"
      },
      "execution_count": 148,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sequential(\n",
            "  (0): Linear(in_features=3, out_features=5, bias=True)\n",
            "  (1): Sigmoid()\n",
            "  (2): Sequential(\n",
            "    (0): Linear(in_features=5, out_features=2, bias=True)\n",
            "    (1): Sigmoid()\n",
            "  )\n",
            ")\n",
            "Linear(in_features=5, out_features=2, bias=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### C. 获取指定模块的学习参数"
      ],
      "metadata": {
        "id": "2bzlLfCQPJmA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.6 关闭梯度（冻结层）"
      ],
      "metadata": {
        "id": "SoFOisOUPQbE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3 实例：BPNN 神经网络的 4 种构建方法及分析"
      ],
      "metadata": {
        "id": "ueIiRnGDPbU4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.1 BPNN 神经网络的 4 种构建方法"
      ],
      "metadata": {
        "id": "Mnxcy200PeI3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "定义一个 单隐层神经网络，4 种方式\n",
        "\n",
        "- 方式 1: 使用 `nn.Sequential()`\n",
        "\n",
        "- 方式 2: 全部使用 层类（`nn.Module` 类）\n",
        "\n",
        "- 方式 3：使用函数类型：`torch.sigmoid()` 和 `torch.flatten()`\n",
        "\n",
        "- 方式 4：使用 `nn.Parameter()`"
      ],
      "metadata": {
        "id": "FwE4PmOYFImb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### A 方式 1：使用 `nn.Sequential()`"
      ],
      "metadata": {
        "id": "3zmsxqYSPlkO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 方式 1: 使用 nn.Sequential()\n",
        "class BPNNModeler(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
        "\n",
        "        super(BPNNModeler, self).__init__()\n",
        "\n",
        "        self.model = nn.Sequential(\n",
        "            nn.Linear(input_dim, hidden_dim), \n",
        "            nn.Sigmoid(),\n",
        "            nn.Linear(hidden_dim, output_dim), \n",
        "            nn.Sigmoid(),\n",
        "            nn.Flatten(0, -1)\n",
        "        )\n",
        "    \n",
        "    # 正向传播\n",
        "    def forward(self, x):\n",
        "        out = self.model(x)\n",
        "        return out\n",
        "# =============================================================================="
      ],
      "metadata": {
        "id": "NjZibFRIPnMk"
      },
      "execution_count": 149,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### B 方式 2：全部使用 层类"
      ],
      "metadata": {
        "id": "xPR132YePnob"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 方式 2: 全部使用 层类（nn.Module 类）\n",
        "class BPNNModeler2(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
        "\n",
        "        super(BPNNModeler2, self).__init__()\n",
        "\n",
        "        # Layer 1\n",
        "        self.layer1_linear = nn.Linear(input_dim, hidden_dim)\n",
        "        self.layer1_sigmoid = nn.Sigmoid()\n",
        "        # Layer 2\n",
        "        self.layer2_linear = nn.Linear(hidden_dim, output_dim)\n",
        "        self.layer2_sigmoid = nn.Sigmoid()\n",
        "        # Output\n",
        "        self.layer2_flattern = nn.Flatten(0, -1)\n",
        "    \n",
        "    # 正向传播\n",
        "    def forward(self, x):\n",
        "        # Layer 1\n",
        "        out_layer1 = self.layer1_linear(x)\n",
        "        out_layer1 = self.layer1_sigmoid(out_layer1)\n",
        "        # Layer 2\n",
        "        out_layer2 = self.layer2_linear(out_layer1)\n",
        "        out_layer2 = self.layer2_sigmoid(out_layer2)\n",
        "        # Output\n",
        "        out = self.layer2_flattern(out_layer2)\n",
        "        return out\n",
        "# =============================================================================="
      ],
      "metadata": {
        "id": "5hfUsHB7PxuX"
      },
      "execution_count": 150,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### C 方式 3：使用函数类型：`torch.sigmoid()` 和 `torch.flatten()`"
      ],
      "metadata": {
        "id": "DXX_G2JsPx0b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 方式 3：使用函数类型：torch.sigmoid() 和 torch.flatten()\n",
        "class BPNNModeler3(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
        "\n",
        "        super(BPNNModeler3, self).__init__()\n",
        "        # Layer 1\n",
        "        self.layer1_linear = nn.Linear(input_dim, hidden_dim)\n",
        "        # Layer 2\n",
        "        self.layer2_linear = nn.Linear(hidden_dim, output_dim)\n",
        "\n",
        "    # 正向传播\n",
        "    def forward(self, x):\n",
        "        # Layer 1\n",
        "        out_layer1 = torch.sigmoid(self.layer1_linear(x))\n",
        "        # Layer 2\n",
        "        out_layer2 = torch.sigmoid(self.layer2_linear(out_layer1))\n",
        "        # Output\n",
        "        out = torch.flatten(out_layer2)\n",
        "        return out\n",
        "# =============================================================================="
      ],
      "metadata": {
        "id": "wIZDUA54P1YW"
      },
      "execution_count": 151,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### D 方式 4：使用 `nn.Parameter()`"
      ],
      "metadata": {
        "id": "y-VRvOx0P1fj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 方式 4：使用 nn.Parameter()\n",
        "class BPNNModeler4(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
        "\n",
        "        super(BPNNModeler4, self).__init__()\n",
        "        # Layer 1\n",
        "        self.w1 = nn.Parameter(torch.rand((input_dim, hidden_dim)))\n",
        "        self.b1 = nn.Parameter(torch.rand(hidden_dim))\n",
        "        # Layer 2\n",
        "        self.w2 = nn.Parameter(torch.rand((hidden_dim, output_dim)))\n",
        "        self.b2 = nn.Parameter(torch.rand(hidden_dim))\n",
        "    \n",
        "    # 正向传播\n",
        "    def forward(self, x):\n",
        "        # Layer 1\n",
        "        out_layer1 = torch.mm(x, self.w1) + self.b1\n",
        "        out_layer1 = torch.sigmoid(out_layer1)\n",
        "        # Layer 2\n",
        "        out_layer2 = torch.mm(out_layer1, self.w2) + self.b2\n",
        "        out_layer2 = torch.sigmoid(out_layer2)\n",
        "        # Output\n",
        "        out = torch.flatten(out_layer2)\n",
        "        return out\n",
        "# =============================================================================="
      ],
      "metadata": {
        "id": "hjTURqMwPI9X"
      },
      "execution_count": 152,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.2 区别"
      ],
      "metadata": {
        "id": "4Se5GGtnQONl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def print_info(model):\n",
        "\n",
        "    print(\"---------.parameters() 方法-------------------\")\n",
        "    for param in model.parameters():\n",
        "        print(type(param), param.data.size())\n",
        "\n",
        "    print(\"---------.named_parameters() 方法-------------\")\n",
        "    for name, param in model.named_parameters():\n",
        "        print(type(param), name, param.data.size())\n",
        "    \n",
        "    print(\"---------.state_dict() 方法-------------------\")\n",
        "    for name, tensor in model.state_dict().items():\n",
        "        print(type(tensor), name, tensor.size())\n",
        "\n",
        "    print(\"---------.modules() 方法----------------------\")\n",
        "    for module in model.modules():\n",
        "        print(type(module), module)\n",
        "\n",
        "    print(\"---------.named_modules() 方法----------------\")\n",
        "    for name, module in model.named_modules():\n",
        "        print(type(module), name, module)\n",
        "\n",
        "    print(\"---------.named_children() 方法----------------\")\n",
        "    for name, module in model.named_children():\n",
        "        print(type(module), name, module)"
      ],
      "metadata": {
        "id": "N3I92909Yi_7"
      },
      "execution_count": 153,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 神经网络模型参数\n",
        "HIDDEN_DIM = 10\n",
        "INPUT_DIM = 5     \n",
        "OUTPUT_DIM = 1\n",
        "\n",
        "\n",
        "# 实例化一个神经网络模型\n",
        "model = BPNNModeler(input_dim=INPUT_DIM, hidden_dim=HIDDEN_DIM, output_dim=OUTPUT_DIM)\n",
        "\n",
        "model2 = BPNNModeler2(input_dim=INPUT_DIM, hidden_dim=HIDDEN_DIM, output_dim=OUTPUT_DIM)\n",
        "\n",
        "model3 = BPNNModeler3(input_dim=INPUT_DIM, hidden_dim=HIDDEN_DIM, output_dim=OUTPUT_DIM)\n",
        "\n",
        "model4 = BPNNModeler4(input_dim=INPUT_DIM, hidden_dim=HIDDEN_DIM, output_dim=OUTPUT_DIM)\n",
        "\n",
        "\n",
        "print_info(model)\n",
        "\n",
        "print_info(model2)\n",
        "\n",
        "print_info(model3)\n",
        "\n",
        "print_info(model4)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pb-eZXZFFPUe",
        "outputId": "ddedc4e9-a9f3-427d-9a80-1e2f85034099"
      },
      "execution_count": 154,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---------.parameters() 方法-------------------\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([10, 5])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([10])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([1, 10])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([1])\n",
            "---------.named_parameters() 方法-------------\n",
            "<class 'torch.nn.parameter.Parameter'> model.0.weight torch.Size([10, 5])\n",
            "<class 'torch.nn.parameter.Parameter'> model.0.bias torch.Size([10])\n",
            "<class 'torch.nn.parameter.Parameter'> model.2.weight torch.Size([1, 10])\n",
            "<class 'torch.nn.parameter.Parameter'> model.2.bias torch.Size([1])\n",
            "---------.state_dict() 方法-------------------\n",
            "<class 'torch.Tensor'> model.0.weight torch.Size([10, 5])\n",
            "<class 'torch.Tensor'> model.0.bias torch.Size([10])\n",
            "<class 'torch.Tensor'> model.2.weight torch.Size([1, 10])\n",
            "<class 'torch.Tensor'> model.2.bias torch.Size([1])\n",
            "---------.modules() 方法----------------------\n",
            "<class '__main__.BPNNModeler'> BPNNModeler(\n",
            "  (model): Sequential(\n",
            "    (0): Linear(in_features=5, out_features=10, bias=True)\n",
            "    (1): Sigmoid()\n",
            "    (2): Linear(in_features=10, out_features=1, bias=True)\n",
            "    (3): Sigmoid()\n",
            "    (4): Flatten(start_dim=0, end_dim=-1)\n",
            "  )\n",
            ")\n",
            "<class 'torch.nn.modules.container.Sequential'> Sequential(\n",
            "  (0): Linear(in_features=5, out_features=10, bias=True)\n",
            "  (1): Sigmoid()\n",
            "  (2): Linear(in_features=10, out_features=1, bias=True)\n",
            "  (3): Sigmoid()\n",
            "  (4): Flatten(start_dim=0, end_dim=-1)\n",
            ")\n",
            "<class 'torch.nn.modules.linear.Linear'> Linear(in_features=5, out_features=10, bias=True)\n",
            "<class 'torch.nn.modules.activation.Sigmoid'> Sigmoid()\n",
            "<class 'torch.nn.modules.linear.Linear'> Linear(in_features=10, out_features=1, bias=True)\n",
            "<class 'torch.nn.modules.activation.Sigmoid'> Sigmoid()\n",
            "<class 'torch.nn.modules.flatten.Flatten'> Flatten(start_dim=0, end_dim=-1)\n",
            "---------.named_modules() 方法----------------\n",
            "<class '__main__.BPNNModeler'>  BPNNModeler(\n",
            "  (model): Sequential(\n",
            "    (0): Linear(in_features=5, out_features=10, bias=True)\n",
            "    (1): Sigmoid()\n",
            "    (2): Linear(in_features=10, out_features=1, bias=True)\n",
            "    (3): Sigmoid()\n",
            "    (4): Flatten(start_dim=0, end_dim=-1)\n",
            "  )\n",
            ")\n",
            "<class 'torch.nn.modules.container.Sequential'> model Sequential(\n",
            "  (0): Linear(in_features=5, out_features=10, bias=True)\n",
            "  (1): Sigmoid()\n",
            "  (2): Linear(in_features=10, out_features=1, bias=True)\n",
            "  (3): Sigmoid()\n",
            "  (4): Flatten(start_dim=0, end_dim=-1)\n",
            ")\n",
            "<class 'torch.nn.modules.linear.Linear'> model.0 Linear(in_features=5, out_features=10, bias=True)\n",
            "<class 'torch.nn.modules.activation.Sigmoid'> model.1 Sigmoid()\n",
            "<class 'torch.nn.modules.linear.Linear'> model.2 Linear(in_features=10, out_features=1, bias=True)\n",
            "<class 'torch.nn.modules.activation.Sigmoid'> model.3 Sigmoid()\n",
            "<class 'torch.nn.modules.flatten.Flatten'> model.4 Flatten(start_dim=0, end_dim=-1)\n",
            "---------.named_children() 方法----------------\n",
            "<class 'torch.nn.modules.container.Sequential'> model Sequential(\n",
            "  (0): Linear(in_features=5, out_features=10, bias=True)\n",
            "  (1): Sigmoid()\n",
            "  (2): Linear(in_features=10, out_features=1, bias=True)\n",
            "  (3): Sigmoid()\n",
            "  (4): Flatten(start_dim=0, end_dim=-1)\n",
            ")\n",
            "---------.parameters() 方法-------------------\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([10, 5])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([10])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([1, 10])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([1])\n",
            "---------.named_parameters() 方法-------------\n",
            "<class 'torch.nn.parameter.Parameter'> layer1_linear.weight torch.Size([10, 5])\n",
            "<class 'torch.nn.parameter.Parameter'> layer1_linear.bias torch.Size([10])\n",
            "<class 'torch.nn.parameter.Parameter'> layer2_linear.weight torch.Size([1, 10])\n",
            "<class 'torch.nn.parameter.Parameter'> layer2_linear.bias torch.Size([1])\n",
            "---------.state_dict() 方法-------------------\n",
            "<class 'torch.Tensor'> layer1_linear.weight torch.Size([10, 5])\n",
            "<class 'torch.Tensor'> layer1_linear.bias torch.Size([10])\n",
            "<class 'torch.Tensor'> layer2_linear.weight torch.Size([1, 10])\n",
            "<class 'torch.Tensor'> layer2_linear.bias torch.Size([1])\n",
            "---------.modules() 方法----------------------\n",
            "<class '__main__.BPNNModeler2'> BPNNModeler2(\n",
            "  (layer1_linear): Linear(in_features=5, out_features=10, bias=True)\n",
            "  (layer1_sigmoid): Sigmoid()\n",
            "  (layer2_linear): Linear(in_features=10, out_features=1, bias=True)\n",
            "  (layer2_sigmoid): Sigmoid()\n",
            "  (layer2_flattern): Flatten(start_dim=0, end_dim=-1)\n",
            ")\n",
            "<class 'torch.nn.modules.linear.Linear'> Linear(in_features=5, out_features=10, bias=True)\n",
            "<class 'torch.nn.modules.activation.Sigmoid'> Sigmoid()\n",
            "<class 'torch.nn.modules.linear.Linear'> Linear(in_features=10, out_features=1, bias=True)\n",
            "<class 'torch.nn.modules.activation.Sigmoid'> Sigmoid()\n",
            "<class 'torch.nn.modules.flatten.Flatten'> Flatten(start_dim=0, end_dim=-1)\n",
            "---------.named_modules() 方法----------------\n",
            "<class '__main__.BPNNModeler2'>  BPNNModeler2(\n",
            "  (layer1_linear): Linear(in_features=5, out_features=10, bias=True)\n",
            "  (layer1_sigmoid): Sigmoid()\n",
            "  (layer2_linear): Linear(in_features=10, out_features=1, bias=True)\n",
            "  (layer2_sigmoid): Sigmoid()\n",
            "  (layer2_flattern): Flatten(start_dim=0, end_dim=-1)\n",
            ")\n",
            "<class 'torch.nn.modules.linear.Linear'> layer1_linear Linear(in_features=5, out_features=10, bias=True)\n",
            "<class 'torch.nn.modules.activation.Sigmoid'> layer1_sigmoid Sigmoid()\n",
            "<class 'torch.nn.modules.linear.Linear'> layer2_linear Linear(in_features=10, out_features=1, bias=True)\n",
            "<class 'torch.nn.modules.activation.Sigmoid'> layer2_sigmoid Sigmoid()\n",
            "<class 'torch.nn.modules.flatten.Flatten'> layer2_flattern Flatten(start_dim=0, end_dim=-1)\n",
            "---------.named_children() 方法----------------\n",
            "<class 'torch.nn.modules.linear.Linear'> layer1_linear Linear(in_features=5, out_features=10, bias=True)\n",
            "<class 'torch.nn.modules.activation.Sigmoid'> layer1_sigmoid Sigmoid()\n",
            "<class 'torch.nn.modules.linear.Linear'> layer2_linear Linear(in_features=10, out_features=1, bias=True)\n",
            "<class 'torch.nn.modules.activation.Sigmoid'> layer2_sigmoid Sigmoid()\n",
            "<class 'torch.nn.modules.flatten.Flatten'> layer2_flattern Flatten(start_dim=0, end_dim=-1)\n",
            "---------.parameters() 方法-------------------\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([10, 5])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([10])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([1, 10])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([1])\n",
            "---------.named_parameters() 方法-------------\n",
            "<class 'torch.nn.parameter.Parameter'> layer1_linear.weight torch.Size([10, 5])\n",
            "<class 'torch.nn.parameter.Parameter'> layer1_linear.bias torch.Size([10])\n",
            "<class 'torch.nn.parameter.Parameter'> layer2_linear.weight torch.Size([1, 10])\n",
            "<class 'torch.nn.parameter.Parameter'> layer2_linear.bias torch.Size([1])\n",
            "---------.state_dict() 方法-------------------\n",
            "<class 'torch.Tensor'> layer1_linear.weight torch.Size([10, 5])\n",
            "<class 'torch.Tensor'> layer1_linear.bias torch.Size([10])\n",
            "<class 'torch.Tensor'> layer2_linear.weight torch.Size([1, 10])\n",
            "<class 'torch.Tensor'> layer2_linear.bias torch.Size([1])\n",
            "---------.modules() 方法----------------------\n",
            "<class '__main__.BPNNModeler3'> BPNNModeler3(\n",
            "  (layer1_linear): Linear(in_features=5, out_features=10, bias=True)\n",
            "  (layer2_linear): Linear(in_features=10, out_features=1, bias=True)\n",
            ")\n",
            "<class 'torch.nn.modules.linear.Linear'> Linear(in_features=5, out_features=10, bias=True)\n",
            "<class 'torch.nn.modules.linear.Linear'> Linear(in_features=10, out_features=1, bias=True)\n",
            "---------.named_modules() 方法----------------\n",
            "<class '__main__.BPNNModeler3'>  BPNNModeler3(\n",
            "  (layer1_linear): Linear(in_features=5, out_features=10, bias=True)\n",
            "  (layer2_linear): Linear(in_features=10, out_features=1, bias=True)\n",
            ")\n",
            "<class 'torch.nn.modules.linear.Linear'> layer1_linear Linear(in_features=5, out_features=10, bias=True)\n",
            "<class 'torch.nn.modules.linear.Linear'> layer2_linear Linear(in_features=10, out_features=1, bias=True)\n",
            "---------.named_children() 方法----------------\n",
            "<class 'torch.nn.modules.linear.Linear'> layer1_linear Linear(in_features=5, out_features=10, bias=True)\n",
            "<class 'torch.nn.modules.linear.Linear'> layer2_linear Linear(in_features=10, out_features=1, bias=True)\n",
            "---------.parameters() 方法-------------------\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([5, 10])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([10])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([10, 1])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([10])\n",
            "---------.named_parameters() 方法-------------\n",
            "<class 'torch.nn.parameter.Parameter'> w1 torch.Size([5, 10])\n",
            "<class 'torch.nn.parameter.Parameter'> b1 torch.Size([10])\n",
            "<class 'torch.nn.parameter.Parameter'> w2 torch.Size([10, 1])\n",
            "<class 'torch.nn.parameter.Parameter'> b2 torch.Size([10])\n",
            "---------.state_dict() 方法-------------------\n",
            "<class 'torch.Tensor'> w1 torch.Size([5, 10])\n",
            "<class 'torch.Tensor'> b1 torch.Size([10])\n",
            "<class 'torch.Tensor'> w2 torch.Size([10, 1])\n",
            "<class 'torch.Tensor'> b2 torch.Size([10])\n",
            "---------.modules() 方法----------------------\n",
            "<class '__main__.BPNNModeler4'> BPNNModeler4()\n",
            "---------.named_modules() 方法----------------\n",
            "<class '__main__.BPNNModeler4'>  BPNNModeler4()\n",
            "---------.named_children() 方法----------------\n"
          ]
        }
      ]
    }
  ]
}