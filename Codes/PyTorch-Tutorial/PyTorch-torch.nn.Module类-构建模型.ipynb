{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PyTorch-torch.nn.Module类-构建模型.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyNBTZ4SLjQUOu4P/MN2b0BZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/veager/StudyNotes/blob/new/Codes/PyTorch-Tutorial/PyTorch-torch.nn.Module%E7%B1%BB-%E6%9E%84%E5%BB%BA%E6%A8%A1%E5%9E%8B.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "PyTorch torch.nn.Module 类 构建模型\n",
        "\n",
        "参考资料：\n",
        "\n",
        "- GitHub：Codes/PyTorch-Tutorial/PyTorch-torch.nn.Module类-构建模型.ipynb\n",
        "\n",
        "- 博客：PyTorch torch.nn.Module 类 构建模型，[地址](https://www.cnblogs.com/veager/articles/16305187.html)"
      ],
      "metadata": {
        "id": "gwaGEdPqEy-w"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 0 加载数据"
      ],
      "metadata": {
        "id": "UxdXJYwHIDML"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F"
      ],
      "metadata": {
        "id": "84wmVTGLFS7E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 0.1 加载 Iris 数据集"
      ],
      "metadata": {
        "id": "C7i7XtmoISUG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_diabetes\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "data = load_diabetes()\n",
        "X = data.data\n",
        "Y = data.target\n",
        "\n",
        "# 将输入输出数据归一化到 [0, 1] 之间\n",
        "scaler_X = MinMaxScaler().fit(X)\n",
        "scaler_Y = MinMaxScaler().fit(np.expand_dims(Y, axis=1))\n",
        "\n",
        "Xs = scaler_X.transform(X)\n",
        "Ys = scaler_Y.transform(np.expand_dims(Y, axis=1))\n",
        "\n",
        "print(Xs.shape, Ys.shape)\n",
        "print(Xs[:5], Ys[:5])\n",
        "print(pd.DataFrame(Xs).describe(), pd.DataFrame(Ys).describe())\n",
        "\n",
        "# 将数据转换为 tensor 类型 \n",
        "Xs_tensor = torch.tensor(Xs, dtype=torch.float)\n",
        "Ys_tensor = torch.tensor(Ys, dtype=torch.float)"
      ],
      "metadata": {
        "id": "ugyTu1xpZ4vG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "01b11a39-be40-4de4-9304-40c23142f86e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(442, 10) (442, 1)\n",
            "[[0.66666667 1.         0.58264463 0.54929577 0.29411765 0.25697211\n",
            "  0.20779221 0.28208745 0.56221737 0.43939394]\n",
            " [0.48333333 0.         0.14876033 0.35211268 0.42156863 0.30677291\n",
            "  0.62337662 0.14104372 0.22244301 0.16666667]\n",
            " [0.88333333 1.         0.51652893 0.43661972 0.28921569 0.25896414\n",
            "  0.24675325 0.28208745 0.49658437 0.40909091]\n",
            " [0.08333333 0.         0.30165289 0.30985915 0.49509804 0.44721116\n",
            "  0.23376623 0.42313117 0.57293604 0.46969697]\n",
            " [0.51666667 0.         0.20661157 0.54929577 0.46568627 0.41733068\n",
            "  0.38961039 0.28208745 0.36236911 0.33333333]] [[0.39252336]\n",
            " [0.15576324]\n",
            " [0.36137072]\n",
            " [0.56386293]\n",
            " [0.34267913]]\n",
            "                0           1           2           3           4           5  \\\n",
            "count  442.000000  442.000000  442.000000  442.000000  442.000000  442.000000   \n",
            "mean     0.491968    0.468326    0.346107    0.459818    0.451668    0.367725   \n",
            "std      0.218484    0.499561    0.182567    0.194806    0.169647    0.151460   \n",
            "min      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
            "25%      0.320833    0.000000    0.214876    0.309859    0.329657    0.271165   \n",
            "50%      0.516667    0.000000    0.318182    0.436620    0.436275    0.355578   \n",
            "75%      0.666667    1.000000    0.465909    0.605634    0.552696    0.462649   \n",
            "max      1.000000    1.000000    1.000000    1.000000    1.000000    1.000000   \n",
            "\n",
            "                6           7           8           9  \n",
            "count  442.000000  442.000000  442.000000  442.000000  \n",
            "mean     0.360889    0.291996    0.485557    0.503942  \n",
            "std      0.167977    0.182010    0.183364    0.174187  \n",
            "min      0.000000    0.000000    0.000000    0.000000  \n",
            "25%      0.237013    0.141044    0.357528    0.382576  \n",
            "50%      0.337662    0.282087    0.478057    0.500000  \n",
            "75%      0.464286    0.423131    0.610446    0.606061  \n",
            "max      1.000000    1.000000    1.000000    1.000000                   0\n",
            "count  442.000000\n",
            "mean     0.396054\n",
            "std      0.240165\n",
            "min      0.000000\n",
            "25%      0.193146\n",
            "50%      0.359813\n",
            "75%      0.580997\n",
            "max      1.000000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 0.2 全局参数设置"
      ],
      "metadata": {
        "id": "Xf0kFGsGKWna"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 样本信息，划分的数据集\n",
        "N_SAMPLE = Xs_tensor.size()[0]              # 样本总数\n",
        "N_TRAIN = int(N_SAMPLE * 0.7)               # 训练样本数\n",
        "N_VALID = int(N_SAMPLE * 0.2)               # 验证样本数\n",
        "N_TEST = N_SAMPLE - N_TRAIN - N_VALID       # 测试样本数\n",
        "\n",
        "\n",
        "# 训练过程超参数设置\n",
        "BATCH_SIZE = 64\n",
        "N_EPOCH = 1000\n",
        "LEARNING_RATE = 0.05\n",
        "\n",
        "\n",
        "# 神经网络模型参数\n",
        "HIDDEN_DIM = 4\n",
        "INPUT_DIM = Xs_tensor.size()[1]     # sizes of input data and output data\n",
        "OUTPUT_DIM = Ys_tensor.size()[1]\n",
        "print(\"NN Structure:\", INPUT_DIM, HIDDEN_DIM, OUTPUT_DIM)\n",
        "\n",
        "\n",
        "# 设置 device，如果 GPU 可用，则使用\n",
        "DEVICE = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "print(\"device:\", DEVICE)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R5U3xRjEKVxF",
        "outputId": "c13e0759-8676-48e6-e5b2-65080bd1b3c9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NN Structure: 10 4 1\n",
            "device: cuda:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 0.3 创建结构化数据"
      ],
      "metadata": {
        "id": "FaMqo_x-Ioej"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import TensorDataset, Dataset, random_split, DataLoader\n",
        "from torch.utils.data.dataloader import default_collate\n",
        "\n",
        "# DataSet 类\n",
        "ds = TensorDataset(Xs_tensor, Ys_tensor)\n",
        "\n",
        "# split training, validation, testing data\n",
        "ds_train, ds_vaild, ds_test = random_split(ds, lengths=[N_TRAIN, N_VALID, N_TEST])\n",
        "print(len(ds_train), len(ds_vaild), len(ds_test))\n",
        "\n",
        "\n",
        "# DataLoader of train data, valid data, test data\n",
        "dl_train = DataLoader(ds_train, batch_size = BATCH_SIZE, shuffle = True,\n",
        "    collate_fn = lambda x: tuple(x_.to(DEVICE) for x_ in default_collate(x))\n",
        "    )\n",
        "\n",
        "dl_valid = DataLoader(ds_vaild, batch_size = BATCH_SIZE, # default shuffle = False,\n",
        "    collate_fn = lambda x: tuple(x_.to(DEVICE) for x_ in default_collate(x))\n",
        "    )\n",
        "\n",
        "dl_test = DataLoader(ds_test, batch_size = BATCH_SIZE, # default shuffle = False,\n",
        "    collate_fn = lambda x: tuple(x_.to(DEVICE) for x_ in default_collate(x))\n",
        "    )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3ngWqkICIYbz",
        "outputId": "57ab5fc6-6a0e-4754-b66c-c508edbb8969"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "309 88 45\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 0.4 定义模型"
      ],
      "metadata": {
        "id": "z_BqissYIaGp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 方式 2: 全部使用 层类（nn.Module 类）\n",
        "class BPNNModeler2(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
        "\n",
        "        super(BPNNModeler2, self).__init__()\n",
        "\n",
        "        # Layer 1\n",
        "        self.layer1_linear = nn.Linear(input_dim, hidden_dim)\n",
        "        self.layer1_sigmoid = nn.Sigmoid()\n",
        "        # Layer 2\n",
        "        self.layer2_linear = nn.Linear(hidden_dim, output_dim)\n",
        "        self.layer2_sigmoid = nn.Sigmoid()\n",
        "        # Output\n",
        "        self.layer2_flattern = nn.Flatten(0, -1)\n",
        "    \n",
        "    # 正向传播\n",
        "    def forward(self, x):\n",
        "        # Layer 1\n",
        "        out_layer1 = self.layer1_linear(x)\n",
        "        out_layer1 = self.layer1_sigmoid(out_layer1)\n",
        "        # Layer 2\n",
        "        out_layer2 = self.layer2_linear(out_layer1)\n",
        "        out_layer2 = self.layer2_sigmoid(out_layer2)\n",
        "        # Output\n",
        "        out = self.layer2_flattern(out_layer2)\n",
        "        return out\n",
        "# =============================================================================="
      ],
      "metadata": {
        "id": "3AiyB78lIXa2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 0.4.1 初始化模型"
      ],
      "metadata": {
        "id": "qfQ_PEy3LYoM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 定义模型\n",
        "model = BPNNModeler2(input_dim = INPUT_DIM, hidden_dim = HIDDEN_DIM, output_dim = OUTPUT_DIM)\n",
        "model = model.to(DEVICE)"
      ],
      "metadata": {
        "id": "0xniWxzQKikG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 0.5 定义损失函数"
      ],
      "metadata": {
        "id": "kOBsRGv-I2wv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 定义 损失函数 MSE 损失\n",
        "def loss_func(model_out, target, reduction='mean'):\n",
        "    loss = F.mse_loss(model_out, target, reduction=reduction) \n",
        "    return loss"
      ],
      "metadata": {
        "id": "_mf3sHJ3I1C7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1 基本框架"
      ],
      "metadata": {
        "id": "-p1IkD9lJBGh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MyModel(torch.nn.Module):\n",
        "    def __init__(self, params):\n",
        "        # params 传入模型的参数\n",
        "        super(MyModel, self).__init__()\n",
        "\t# 放入需要学习的参数，一般由 nn.Layer() 或 nn.Parameter() 定义\n",
        "    \n",
        "    # 正向传播\n",
        "    def forward(self, x):\n",
        "        # x: 为传入的数据，第1个维度（x.size()[0]）为 batch size\n",
        "        # 根据定义的参数，确定数据的传入顺序，构建模型\n",
        "        return out\n",
        "    \n",
        "    # 损失函数\n",
        "    def loss_func(self, out, target):\n",
        "        # out：模型的输出，一般为预测值\n",
        "        # target: 输出所对应的真实值\n",
        "        return loss\n",
        "    \n",
        "    # 预测类别，用于分类模型\n",
        "    def pred_label(self, prob):\n",
        "        # 分类模型的 out 通常为 [0,1] 之间的概率形式，通过 torch.argmax() 函数也获取概率最大的标签\n",
        "        label = torch.argmax(prob, dim, keepdim=False)\n",
        "        return label"
      ],
      "metadata": {
        "id": "t5TP1MajJMwI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2 方法"
      ],
      "metadata": {
        "id": "LzjMFWRPJN4m"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.1 `torch.nn.Module()` 类主要方法"
      ],
      "metadata": {
        "id": "Q-JWvAIvJTcJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.2 `.zero_grad()` 方法使用"
      ],
      "metadata": {
        "id": "8titi_onJYsH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**实例 1**： 使用 `optimizer.zero_grad()`"
      ],
      "metadata": {
        "id": "7QYjXc8gJjBP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "N_EPOCH = 50\n",
        "LEARNING_RATE = 0.1\n",
        "\n",
        "# 定义优化器，模型参数 model.parameters() 传入到优化器中\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=LEARNING_RATE)  # model: 已定义的模型\n",
        "\n",
        "for epoch in range(N_EPOCH):\n",
        "\n",
        "    train_total_loss = 0.\n",
        "\n",
        "    for i, (X_batch, Y_batch) in enumerate(dl_train):    # dl_train: 已定义的 DataLoader 类\n",
        "        optimizer.zero_grad()    # 优化器中的模型参数的梯度归零\n",
        "\n",
        "        out = model(X_batch)                           \n",
        "        loss = loss_func(out, Y_batch.flatten())  \n",
        "        loss.backward()          # 反向传播，计算梯度\n",
        "        \n",
        "        optimizer.step()         # 执行一步优化，更新参数\n",
        "\n",
        "        train_total_loss += loss.item()\n",
        "\n",
        "    # Print Traing information\n",
        "    if (epoch + 1) % 1 == 0:\n",
        "        print('Epoch: {0:>4}, Train Loss: {1:>10.5f}'.format(epoch+1, train_total_loss))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S5kdXSldJTCT",
        "outputId": "d7c6cbea-814d-4659-a1d9-dcddc1784dca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch:    1, Train Loss:    0.37416\n",
            "Epoch:    2, Train Loss:    0.35511\n",
            "Epoch:    3, Train Loss:    0.34071\n",
            "Epoch:    4, Train Loss:    0.32747\n",
            "Epoch:    5, Train Loss:    0.32199\n",
            "Epoch:    6, Train Loss:    0.31627\n",
            "Epoch:    7, Train Loss:    0.31178\n",
            "Epoch:    8, Train Loss:    0.30900\n",
            "Epoch:    9, Train Loss:    0.30481\n",
            "Epoch:   10, Train Loss:    0.30476\n",
            "Epoch:   11, Train Loss:    0.30285\n",
            "Epoch:   12, Train Loss:    0.30226\n",
            "Epoch:   13, Train Loss:    0.30088\n",
            "Epoch:   14, Train Loss:    0.29920\n",
            "Epoch:   15, Train Loss:    0.30008\n",
            "Epoch:   16, Train Loss:    0.29815\n",
            "Epoch:   17, Train Loss:    0.29772\n",
            "Epoch:   18, Train Loss:    0.29866\n",
            "Epoch:   19, Train Loss:    0.29792\n",
            "Epoch:   20, Train Loss:    0.29794\n",
            "Epoch:   21, Train Loss:    0.29616\n",
            "Epoch:   22, Train Loss:    0.29995\n",
            "Epoch:   23, Train Loss:    0.29881\n",
            "Epoch:   24, Train Loss:    0.29792\n",
            "Epoch:   25, Train Loss:    0.29626\n",
            "Epoch:   26, Train Loss:    0.29506\n",
            "Epoch:   27, Train Loss:    0.29864\n",
            "Epoch:   28, Train Loss:    0.29864\n",
            "Epoch:   29, Train Loss:    0.29884\n",
            "Epoch:   30, Train Loss:    0.29842\n",
            "Epoch:   31, Train Loss:    0.29864\n",
            "Epoch:   32, Train Loss:    0.29768\n",
            "Epoch:   33, Train Loss:    0.29821\n",
            "Epoch:   34, Train Loss:    0.29781\n",
            "Epoch:   35, Train Loss:    0.29942\n",
            "Epoch:   36, Train Loss:    0.29603\n",
            "Epoch:   37, Train Loss:    0.29724\n",
            "Epoch:   38, Train Loss:    0.29947\n",
            "Epoch:   39, Train Loss:    0.29704\n",
            "Epoch:   40, Train Loss:    0.29496\n",
            "Epoch:   41, Train Loss:    0.29721\n",
            "Epoch:   42, Train Loss:    0.29426\n",
            "Epoch:   43, Train Loss:    0.29773\n",
            "Epoch:   44, Train Loss:    0.29537\n",
            "Epoch:   45, Train Loss:    0.29858\n",
            "Epoch:   46, Train Loss:    0.29435\n",
            "Epoch:   47, Train Loss:    0.29898\n",
            "Epoch:   48, Train Loss:    0.29806\n",
            "Epoch:   49, Train Loss:    0.29690\n",
            "Epoch:   50, Train Loss:    0.29684\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**实例 2**： 使用 `model.zero_grad()`"
      ],
      "metadata": {
        "id": "bfojtkvnKDgh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "N_EPOCH = 50\n",
        "LEARNING_RATE = 0.5\n",
        "\n",
        "for epoch in range(N_EPOCH):\n",
        "\n",
        "    train_total_loss = 0.\n",
        "\n",
        "    for i, (X_batch, Y_batch) in enumerate(dl_train):   # dl_train: 已定义的 DataLoader 类\n",
        "        model.zero_grad()       # 模型参数参数梯度归零    # model: 已定义的模型\n",
        "\n",
        "        out = model(X_batch)                           \n",
        "        loss = loss_func(out, Y_batch.flatten())  \n",
        "        loss.backward()         # 反向传播，计算梯度\n",
        "\n",
        "        with torch.no_grad():   # 更新参数时，要取消梯度追踪\n",
        "            for param in model.parameters():\n",
        "                param -= LEARNING_RATE * param.grad     # 更新参数\n",
        "\n",
        "        train_total_loss += loss.item()\n",
        "\n",
        "    # Print Traing information\n",
        "    if (epoch + 1) % 1 == 0:\n",
        "        print('Epoch: {0:>4}, Train Loss: {1:>10.5f}'.format(epoch+1, train_total_loss))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uVkuQk2bJNdu",
        "outputId": "7a7ac327-8f62-4113-ac57-ba15f31dd3db"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch:    1, Train Loss:    0.30232\n",
            "Epoch:    2, Train Loss:    0.29653\n",
            "Epoch:    3, Train Loss:    0.29755\n",
            "Epoch:    4, Train Loss:    0.29814\n",
            "Epoch:    5, Train Loss:    0.29646\n",
            "Epoch:    6, Train Loss:    0.29829\n",
            "Epoch:    7, Train Loss:    0.29925\n",
            "Epoch:    8, Train Loss:    0.29641\n",
            "Epoch:    9, Train Loss:    0.29618\n",
            "Epoch:   10, Train Loss:    0.29272\n",
            "Epoch:   11, Train Loss:    0.29529\n",
            "Epoch:   12, Train Loss:    0.29557\n",
            "Epoch:   13, Train Loss:    0.29404\n",
            "Epoch:   14, Train Loss:    0.29642\n",
            "Epoch:   15, Train Loss:    0.29439\n",
            "Epoch:   16, Train Loss:    0.29238\n",
            "Epoch:   17, Train Loss:    0.29295\n",
            "Epoch:   18, Train Loss:    0.29500\n",
            "Epoch:   19, Train Loss:    0.29573\n",
            "Epoch:   20, Train Loss:    0.29591\n",
            "Epoch:   21, Train Loss:    0.29823\n",
            "Epoch:   22, Train Loss:    0.29290\n",
            "Epoch:   23, Train Loss:    0.29327\n",
            "Epoch:   24, Train Loss:    0.29579\n",
            "Epoch:   25, Train Loss:    0.29401\n",
            "Epoch:   26, Train Loss:    0.29404\n",
            "Epoch:   27, Train Loss:    0.29444\n",
            "Epoch:   28, Train Loss:    0.29030\n",
            "Epoch:   29, Train Loss:    0.29280\n",
            "Epoch:   30, Train Loss:    0.29202\n",
            "Epoch:   31, Train Loss:    0.29025\n",
            "Epoch:   32, Train Loss:    0.29037\n",
            "Epoch:   33, Train Loss:    0.29097\n",
            "Epoch:   34, Train Loss:    0.29132\n",
            "Epoch:   35, Train Loss:    0.28939\n",
            "Epoch:   36, Train Loss:    0.29276\n",
            "Epoch:   37, Train Loss:    0.29038\n",
            "Epoch:   38, Train Loss:    0.29019\n",
            "Epoch:   39, Train Loss:    0.29023\n",
            "Epoch:   40, Train Loss:    0.29066\n",
            "Epoch:   41, Train Loss:    0.28670\n",
            "Epoch:   42, Train Loss:    0.29091\n",
            "Epoch:   43, Train Loss:    0.28977\n",
            "Epoch:   44, Train Loss:    0.29102\n",
            "Epoch:   45, Train Loss:    0.28932\n",
            "Epoch:   46, Train Loss:    0.28651\n",
            "Epoch:   47, Train Loss:    0.28424\n",
            "Epoch:   48, Train Loss:    0.28672\n",
            "Epoch:   49, Train Loss:    0.28758\n",
            "Epoch:   50, Train Loss:    0.28491\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.3 训练模式和评估模型"
      ],
      "metadata": {
        "id": "u4hg7VfhMP5h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "N_EPOCH = 50\n",
        "LEARNING_RATE = 0.1\n",
        "\n",
        "# 定义优化器\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=LEARNING_RATE)\n",
        "\n",
        "# 模型训练过程\n",
        "for epoch in range(N_EPOCH):\n",
        "    # 模型训练\n",
        "    train_total_loss = 0.\n",
        "\n",
        "    model.train()    # 启动模型训练模式\n",
        "    for i, (X_batch, Y_batch) in enumerate(dl_train):\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        out = model(X_batch)\n",
        "        loss = loss_func(out, Y_batch.flatten())\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        train_total_loss += loss.item()\n",
        "    \n",
        "\n",
        "    # 评估验证集 方式 1: 使用 torch.no_grad()\n",
        "    vaild_total_loss = 0.\n",
        "    \n",
        "    model.eval()    # 启动模型评估模式\n",
        "    with torch.no_grad():\n",
        "        for X_valid, Y_valid in dl_valid:\n",
        "            out = model(X_valid)\n",
        "            loss = loss_func(out, Y_valid.flatten())\n",
        "            vaild_total_loss += loss.item()\n",
        "\n",
        "\n",
        "    # 评估验证集 方式 2: 使用 .detach()\n",
        "    vaild_total_loss = 0.\n",
        "\n",
        "    model.eval()    # 启动模型评估模式\n",
        "    for X_valid, Y_valid in dl_valid:\n",
        "        # X_valid = X_valid.detach()  # 取消对 tensor 的梯度跟踪\n",
        "        # Y_valid = Y_valid.detach()\n",
        "        out = model(X_valid)\n",
        "\n",
        "        # print(X_valid.requires_grad, out.requires_grad)\n",
        "        # Output: False, True\n",
        "\n",
        "        out = out.detach() # 取消对 tensor 的梯度跟踪\n",
        "\n",
        "        loss = loss_func(out, Y_valid.flatten())\n",
        "        vaild_total_loss += loss.item()\n",
        "\n",
        "    if (epoch+1) % 1 == 0:\n",
        "        print(epoch + 1, ':', \n",
        "              round(train_total_loss, 5),\n",
        "              round(vaild_total_loss, 5))"
      ],
      "metadata": {
        "id": "7PKsqvrNcOWU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b23e014a-3395-4689-db13-db760077af44"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1 : 0.28574 0.10303\n",
            "2 : 0.28534 0.10298\n",
            "3 : 0.28559 0.10295\n",
            "4 : 0.28472 0.10293\n",
            "5 : 0.28485 0.10289\n",
            "6 : 0.28374 0.10286\n",
            "7 : 0.28326 0.10284\n",
            "8 : 0.28441 0.10282\n",
            "9 : 0.28756 0.10278\n",
            "10 : 0.28675 0.10274\n",
            "11 : 0.28629 0.10272\n",
            "12 : 0.28579 0.10269\n",
            "13 : 0.28444 0.10268\n",
            "14 : 0.28246 0.10264\n",
            "15 : 0.28409 0.10261\n",
            "16 : 0.284 0.1026\n",
            "17 : 0.28582 0.10256\n",
            "18 : 0.28458 0.10252\n",
            "19 : 0.28587 0.10246\n",
            "20 : 0.28354 0.10242\n",
            "21 : 0.28332 0.10239\n",
            "22 : 0.2855 0.10236\n",
            "23 : 0.28331 0.10232\n",
            "24 : 0.28471 0.10227\n",
            "25 : 0.28137 0.10224\n",
            "26 : 0.28565 0.10221\n",
            "27 : 0.285 0.10217\n",
            "28 : 0.28222 0.10214\n",
            "29 : 0.28187 0.10213\n",
            "30 : 0.28197 0.10211\n",
            "31 : 0.28449 0.10208\n",
            "32 : 0.28121 0.10204\n",
            "33 : 0.28208 0.102\n",
            "34 : 0.28421 0.10197\n",
            "35 : 0.28069 0.10196\n",
            "36 : 0.2813 0.10193\n",
            "37 : 0.28155 0.10192\n",
            "38 : 0.28195 0.10187\n",
            "39 : 0.28237 0.10181\n",
            "40 : 0.28391 0.10175\n",
            "41 : 0.28116 0.10173\n",
            "42 : 0.28197 0.1017\n",
            "43 : 0.28228 0.10165\n",
            "44 : 0.28003 0.10161\n",
            "45 : 0.28203 0.10158\n",
            "46 : 0.28242 0.10154\n",
            "47 : 0.28016 0.10151\n",
            "48 : 0.28093 0.10148\n",
            "49 : 0.28161 0.10144\n",
            "50 : 0.28222 0.1014\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.4 GPU 部署相关"
      ],
      "metadata": {
        "id": "ldVn_DB2NVbO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.5 获取模型参数和模型结构"
      ],
      "metadata": {
        "id": "txrZQbXANYaI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.5.1 获取参数"
      ],
      "metadata": {
        "id": "Obh6DdpwNiXp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### A 遍历所有参数"
      ],
      "metadata": {
        "id": "Es5TnZhpNmOI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "layer_linear = nn.Linear(3, 5)\n",
        "\n",
        "print(\"---------.parameters() 方法-------------------\")\n",
        "for param in layer_linear.parameters():\n",
        "    print(type(param))\n",
        "    print(param.data.size())\n",
        "\n",
        "print(\"---------.named_parameters() 方法-------------\")\n",
        "for name, param in layer_linear.named_parameters():\n",
        "    print(type(param))\n",
        "    print(name, param.data.size())\n",
        "\n",
        "print(\"---------.state_dict() 方法-------------------\")\n",
        "for name, tensor in layer_linear.state_dict().items():\n",
        "    print(type(tensor))\n",
        "    print(name, tensor.size())\n",
        "\n",
        "print(\"---------.state_dict() 方法，遍历参数名--------\")\n",
        "for name in layer_linear.state_dict():\n",
        "    print(name)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cLggCJfuK6LS",
        "outputId": "cd661f49-8034-44c9-818b-58f70dbe8e35"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---------.parameters() 方法-------------------\n",
            "<class 'torch.nn.parameter.Parameter'>\n",
            "torch.Size([5, 3])\n",
            "<class 'torch.nn.parameter.Parameter'>\n",
            "torch.Size([5])\n",
            "---------.named_parameters() 方法-------------\n",
            "<class 'torch.nn.parameter.Parameter'>\n",
            "weight torch.Size([5, 3])\n",
            "<class 'torch.nn.parameter.Parameter'>\n",
            "bias torch.Size([5])\n",
            "---------.state_dict() 方法-------------------\n",
            "<class 'torch.Tensor'>\n",
            "weight torch.Size([5, 3])\n",
            "<class 'torch.Tensor'>\n",
            "bias torch.Size([5])\n",
            "---------.state_dict() 方法，遍历参数名--------\n",
            "weight\n",
            "bias\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "遍历无**学习参数**的 Module，输出为空"
      ],
      "metadata": {
        "id": "Zg7m8tQoOeIz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "layer_act = nn.Sigmoid()\n",
        "\n",
        "print(\"---------.parameters() 方法-------------------\")\n",
        "for param in layer_act.parameters():\n",
        "    print(param.data.size())\n",
        "\n",
        "print(\"---------.named_parameters() 方法-------------\")\n",
        "for name, param in layer_act.named_parameters():\n",
        "    print(name, param.data.size())\n",
        "\n",
        "print(\"---------.state_dict() 方法-------------------\")\n",
        "for name, tensor in layer_act.state_dict().items():\n",
        "    print(type(tensor))\n",
        "    print(name, tensor.size())\n",
        "\n",
        "print(\"---------.state_dict() 方法，遍历参数名--------\")\n",
        "for name in layer_act.state_dict():\n",
        "    print(name)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U1U3o1s8K3ex",
        "outputId": "795a609f-dfd8-453b-a04a-8a1ef1d38495"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---------.parameters() 方法-------------------\n",
            "---------.named_parameters() 方法-------------\n",
            "---------.state_dict() 方法-------------------\n",
            "---------.state_dict() 方法，遍历参数名--------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### B. 获取特定的学习参数"
      ],
      "metadata": {
        "id": "srSvTapgOWXn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(list(layer_linear.parameters())[0].data)\n",
        "\n",
        "print(dict(layer_linear.named_parameters())['weight'].data)\n",
        "\n",
        "print(layer_linear.state_dict()['weight'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k3195dGgO5iX",
        "outputId": "b5e95c49-88f2-4292-e275-3bf11352187e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-0.5668, -0.3317,  0.3824],\n",
            "        [ 0.3101,  0.4283,  0.0551],\n",
            "        [-0.3675,  0.3014,  0.4452],\n",
            "        [ 0.1134,  0.5319,  0.3761],\n",
            "        [ 0.4877, -0.0333, -0.3625]])\n",
            "tensor([[-0.5668, -0.3317,  0.3824],\n",
            "        [ 0.3101,  0.4283,  0.0551],\n",
            "        [-0.3675,  0.3014,  0.4452],\n",
            "        [ 0.1134,  0.5319,  0.3761],\n",
            "        [ 0.4877, -0.0333, -0.3625]])\n",
            "tensor([[-0.5668, -0.3317,  0.3824],\n",
            "        [ 0.3101,  0.4283,  0.0551],\n",
            "        [-0.3675,  0.3014,  0.4452],\n",
            "        [ 0.1134,  0.5319,  0.3761],\n",
            "        [ 0.4877, -0.0333, -0.3625]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.5.2 获取模块"
      ],
      "metadata": {
        "id": "RyXZmVj7O1am"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### A 遍历所有模块"
      ],
      "metadata": {
        "id": "2VW9b_HZOzBA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "contain_seq = nn.Sequential(\n",
        "    nn.Linear(3, 5), \n",
        "    nn.Sigmoid(), \n",
        "    nn.Sequential(\n",
        "        nn.Linear(5, 2), \n",
        "        nn.Sigmoid()\n",
        "    ))\n",
        "\n",
        "print(\"---------.parameters() 方法-------------------\")\n",
        "for param in contain_seq.parameters():\n",
        "    print(type(param))\n",
        "    print(param.data.size())\n",
        "\n",
        "print(\"---------.named_parameters() 方法-------------\")\n",
        "for name, param in contain_seq.named_parameters():\n",
        "    print(type(param))\n",
        "    print(name, param.data.size())\n",
        "\n",
        "print(\"---------.state_dict() 方法-------------------\")\n",
        "for name, tensor in contain_seq.state_dict().items():\n",
        "    print(type(tensor))\n",
        "    print(name, tensor.size())\n",
        "\n",
        "print(\"---------.modules() 方法----------------------\")\n",
        "# 获取模型中的 所有 模块\n",
        "for module in contain_seq.modules():\n",
        "    print(type(module))\n",
        "    print(module)\n",
        "\n",
        "print(\"---------.named_modules() 方法----------------\")\n",
        "# 获取模型中的 所有 模块名 和 模块\n",
        "for name, module in contain_seq.named_modules():\n",
        "    print(type(module))\n",
        "    print(name, module)\n",
        "\n",
        "print(\"---------.named_children() 方法----------------\")\n",
        "# 获取模型中的 直接 子模块名称 和 子模块\n",
        "for name, module in contain_seq.named_children():\n",
        "    print(type(module))\n",
        "    print(name, module)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SOCr2o78K5Oc",
        "outputId": "b765cfe6-98f0-4923-ecfa-ba278a670bea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---------.parameters() 方法-------------------\n",
            "<class 'torch.nn.parameter.Parameter'>\n",
            "torch.Size([5, 3])\n",
            "<class 'torch.nn.parameter.Parameter'>\n",
            "torch.Size([5])\n",
            "<class 'torch.nn.parameter.Parameter'>\n",
            "torch.Size([2, 5])\n",
            "<class 'torch.nn.parameter.Parameter'>\n",
            "torch.Size([2])\n",
            "---------.named_parameters() 方法-------------\n",
            "<class 'torch.nn.parameter.Parameter'>\n",
            "0.weight torch.Size([5, 3])\n",
            "<class 'torch.nn.parameter.Parameter'>\n",
            "0.bias torch.Size([5])\n",
            "<class 'torch.nn.parameter.Parameter'>\n",
            "2.0.weight torch.Size([2, 5])\n",
            "<class 'torch.nn.parameter.Parameter'>\n",
            "2.0.bias torch.Size([2])\n",
            "---------.state_dict() 方法-------------------\n",
            "<class 'torch.Tensor'>\n",
            "0.weight torch.Size([5, 3])\n",
            "<class 'torch.Tensor'>\n",
            "0.bias torch.Size([5])\n",
            "<class 'torch.Tensor'>\n",
            "2.0.weight torch.Size([2, 5])\n",
            "<class 'torch.Tensor'>\n",
            "2.0.bias torch.Size([2])\n",
            "---------.modules() 方法----------------------\n",
            "<class 'torch.nn.modules.container.Sequential'>\n",
            "Sequential(\n",
            "  (0): Linear(in_features=3, out_features=5, bias=True)\n",
            "  (1): Sigmoid()\n",
            "  (2): Sequential(\n",
            "    (0): Linear(in_features=5, out_features=2, bias=True)\n",
            "    (1): Sigmoid()\n",
            "  )\n",
            ")\n",
            "<class 'torch.nn.modules.linear.Linear'>\n",
            "Linear(in_features=3, out_features=5, bias=True)\n",
            "<class 'torch.nn.modules.activation.Sigmoid'>\n",
            "Sigmoid()\n",
            "<class 'torch.nn.modules.container.Sequential'>\n",
            "Sequential(\n",
            "  (0): Linear(in_features=5, out_features=2, bias=True)\n",
            "  (1): Sigmoid()\n",
            ")\n",
            "<class 'torch.nn.modules.linear.Linear'>\n",
            "Linear(in_features=5, out_features=2, bias=True)\n",
            "<class 'torch.nn.modules.activation.Sigmoid'>\n",
            "Sigmoid()\n",
            "---------.named_modules() 方法----------------\n",
            "<class 'torch.nn.modules.container.Sequential'>\n",
            " Sequential(\n",
            "  (0): Linear(in_features=3, out_features=5, bias=True)\n",
            "  (1): Sigmoid()\n",
            "  (2): Sequential(\n",
            "    (0): Linear(in_features=5, out_features=2, bias=True)\n",
            "    (1): Sigmoid()\n",
            "  )\n",
            ")\n",
            "<class 'torch.nn.modules.linear.Linear'>\n",
            "0 Linear(in_features=3, out_features=5, bias=True)\n",
            "<class 'torch.nn.modules.activation.Sigmoid'>\n",
            "1 Sigmoid()\n",
            "<class 'torch.nn.modules.container.Sequential'>\n",
            "2 Sequential(\n",
            "  (0): Linear(in_features=5, out_features=2, bias=True)\n",
            "  (1): Sigmoid()\n",
            ")\n",
            "<class 'torch.nn.modules.linear.Linear'>\n",
            "2.0 Linear(in_features=5, out_features=2, bias=True)\n",
            "<class 'torch.nn.modules.activation.Sigmoid'>\n",
            "2.1 Sigmoid()\n",
            "---------.named_children() 方法----------------\n",
            "<class 'torch.nn.modules.linear.Linear'>\n",
            "0 Linear(in_features=3, out_features=5, bias=True)\n",
            "<class 'torch.nn.modules.activation.Sigmoid'>\n",
            "1 Sigmoid()\n",
            "<class 'torch.nn.modules.container.Sequential'>\n",
            "2 Sequential(\n",
            "  (0): Linear(in_features=5, out_features=2, bias=True)\n",
            "  (1): Sigmoid()\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### B. 获取指定的模块"
      ],
      "metadata": {
        "id": "63WtB77HPBIu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(list(contain_seq.modules())[0])\n",
        "\n",
        "print(dict(contain_seq.named_modules())['2.0'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sFMj9XumOrz9",
        "outputId": "dd341b9a-ddc2-4a70-ea1d-c447d857ac47"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sequential(\n",
            "  (0): Linear(in_features=3, out_features=5, bias=True)\n",
            "  (1): Sigmoid()\n",
            "  (2): Sequential(\n",
            "    (0): Linear(in_features=5, out_features=2, bias=True)\n",
            "    (1): Sigmoid()\n",
            "  )\n",
            ")\n",
            "Linear(in_features=5, out_features=2, bias=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### C. 获取指定模块的学习参数"
      ],
      "metadata": {
        "id": "2bzlLfCQPJmA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.6 关闭梯度（冻结层）"
      ],
      "metadata": {
        "id": "SoFOisOUPQbE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3 实例：BPNN 神经网络的 4 种构建方法及分析"
      ],
      "metadata": {
        "id": "ueIiRnGDPbU4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.1 BPNN 神经网络的 4 种构建方法"
      ],
      "metadata": {
        "id": "Mnxcy200PeI3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "定义一个 单隐层神经网络，4 种方式\n",
        "\n",
        "- 方式 1: 使用 `nn.Sequential()`\n",
        "\n",
        "- 方式 2: 全部使用 层类（`nn.Module` 类）\n",
        "\n",
        "- 方式 3：使用函数类型：`torch.sigmoid()` 和 `torch.flatten()`\n",
        "\n",
        "- 方式 4：使用 `nn.Parameter()`"
      ],
      "metadata": {
        "id": "FwE4PmOYFImb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### A 方式 1：使用 `nn.Sequential()`"
      ],
      "metadata": {
        "id": "3zmsxqYSPlkO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 方式 1: 使用 nn.Sequential()\n",
        "class BPNNModeler(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
        "\n",
        "        super(BPNNModeler, self).__init__()\n",
        "\n",
        "        self.model = nn.Sequential(\n",
        "            nn.Linear(input_dim, hidden_dim), \n",
        "            nn.Sigmoid(),\n",
        "            nn.Linear(hidden_dim, output_dim), \n",
        "            nn.Sigmoid(),\n",
        "            nn.Flatten(0, -1)\n",
        "        )\n",
        "    \n",
        "    # 正向传播\n",
        "    def forward(self, x):\n",
        "        out = self.model(x)\n",
        "        return out\n",
        "# =============================================================================="
      ],
      "metadata": {
        "id": "NjZibFRIPnMk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### B 方式 2：全部使用 层类"
      ],
      "metadata": {
        "id": "xPR132YePnob"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 方式 2: 全部使用 层类（nn.Module 类）\n",
        "class BPNNModeler2(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
        "\n",
        "        super(BPNNModeler2, self).__init__()\n",
        "\n",
        "        # Layer 1\n",
        "        self.layer1_linear = nn.Linear(input_dim, hidden_dim)\n",
        "        self.layer1_sigmoid = nn.Sigmoid()\n",
        "        # Layer 2\n",
        "        self.layer2_linear = nn.Linear(hidden_dim, output_dim)\n",
        "        self.layer2_sigmoid = nn.Sigmoid()\n",
        "        # Output\n",
        "        self.layer2_flattern = nn.Flatten(0, -1)\n",
        "    \n",
        "    # 正向传播\n",
        "    def forward(self, x):\n",
        "        # Layer 1\n",
        "        out_layer1 = self.layer1_linear(x)\n",
        "        out_layer1 = self.layer1_sigmoid(out_layer1)\n",
        "        # Layer 2\n",
        "        out_layer2 = self.layer2_linear(out_layer1)\n",
        "        out_layer2 = self.layer2_sigmoid(out_layer2)\n",
        "        # Output\n",
        "        out = self.layer2_flattern(out_layer2)\n",
        "        return out\n",
        "# =============================================================================="
      ],
      "metadata": {
        "id": "5hfUsHB7PxuX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### C 方式 3：使用函数类型：`torch.sigmoid()` 和 `torch.flatten()`"
      ],
      "metadata": {
        "id": "DXX_G2JsPx0b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 方式 3：使用函数类型：torch.sigmoid() 和 torch.flatten()\n",
        "class BPNNModeler3(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
        "\n",
        "        super(BPNNModeler3, self).__init__()\n",
        "        # Layer 1\n",
        "        self.layer1_linear = nn.Linear(input_dim, hidden_dim)\n",
        "        # Layer 2\n",
        "        self.layer2_linear = nn.Linear(hidden_dim, output_dim)\n",
        "\n",
        "    # 正向传播\n",
        "    def forward(self, x):\n",
        "        # Layer 1\n",
        "        out_layer1 = torch.sigmoid(self.layer1_linear(x))\n",
        "        # Layer 2\n",
        "        out_layer2 = torch.sigmoid(self.layer2_linear(out_layer1))\n",
        "        # Output\n",
        "        out = torch.flatten(out_layer2)\n",
        "        return out\n",
        "# =============================================================================="
      ],
      "metadata": {
        "id": "wIZDUA54P1YW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### D 方式 4：使用 `nn.Parameter()`"
      ],
      "metadata": {
        "id": "y-VRvOx0P1fj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 方式 4：使用 nn.Parameter()\n",
        "class BPNNModeler4(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
        "\n",
        "        super(BPNNModeler4, self).__init__()\n",
        "        # Layer 1\n",
        "        self.w1 = nn.Parameter(torch.rand((input_dim, hidden_dim)))\n",
        "        self.b1 = nn.Parameter(torch.rand(hidden_dim))\n",
        "        # Layer 2\n",
        "        self.w2 = nn.Parameter(torch.rand((hidden_dim, output_dim)))\n",
        "        self.b2 = nn.Parameter(torch.rand(hidden_dim))\n",
        "    \n",
        "    # 正向传播\n",
        "    def forward(self, x):\n",
        "        # Layer 1\n",
        "        out_layer1 = torch.mm(x, self.w1) + self.b1\n",
        "        out_layer1 = torch.sigmoid(out_layer1)\n",
        "        # Layer 2\n",
        "        out_layer2 = torch.mm(out_layer1, self.w2) + self.b2\n",
        "        out_layer2 = torch.sigmoid(out_layer2)\n",
        "        # Output\n",
        "        out = torch.flatten(out_layer2)\n",
        "        return out\n",
        "# =============================================================================="
      ],
      "metadata": {
        "id": "hjTURqMwPI9X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.2 区别"
      ],
      "metadata": {
        "id": "4Se5GGtnQONl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def print_info(model):\n",
        "\n",
        "    print(\"---------.parameters() 方法-------------------\")\n",
        "    for param in model.parameters():\n",
        "        print(type(param), param.data.size())\n",
        "\n",
        "    print(\"---------.named_parameters() 方法-------------\")\n",
        "    for name, param in model.named_parameters():\n",
        "        print(type(param), name, param.data.size())\n",
        "    \n",
        "    print(\"---------.state_dict() 方法-------------------\")\n",
        "    for name, tensor in model.state_dict().items():\n",
        "        print(type(tensor), name, tensor.size())\n",
        "\n",
        "    print(\"---------.modules() 方法----------------------\")\n",
        "    for module in model.modules():\n",
        "        print(type(module), module)\n",
        "\n",
        "    print(\"---------.named_modules() 方法----------------\")\n",
        "    for name, module in model.named_modules():\n",
        "        print(type(module), name, module)\n",
        "\n",
        "    print(\"---------.named_children() 方法----------------\")\n",
        "    for name, module in model.named_children():\n",
        "        print(type(module), name, module)"
      ],
      "metadata": {
        "id": "N3I92909Yi_7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 神经网络模型参数\n",
        "HIDDEN_DIM = 10\n",
        "INPUT_DIM = 5     \n",
        "OUTPUT_DIM = 1\n",
        "\n",
        "\n",
        "# 实例化一个神经网络模型\n",
        "model = BPNNModeler(input_dim=INPUT_DIM, hidden_dim=HIDDEN_DIM, output_dim=OUTPUT_DIM)\n",
        "\n",
        "model2 = BPNNModeler2(input_dim=INPUT_DIM, hidden_dim=HIDDEN_DIM, output_dim=OUTPUT_DIM)\n",
        "\n",
        "model3 = BPNNModeler3(input_dim=INPUT_DIM, hidden_dim=HIDDEN_DIM, output_dim=OUTPUT_DIM)\n",
        "\n",
        "model4 = BPNNModeler4(input_dim=INPUT_DIM, hidden_dim=HIDDEN_DIM, output_dim=OUTPUT_DIM)\n",
        "\n",
        "\n",
        "print_info(model)\n",
        "\n",
        "print_info(model2)\n",
        "\n",
        "print_info(model3)\n",
        "\n",
        "print_info(model4)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pb-eZXZFFPUe",
        "outputId": "15770af5-97c0-4ca1-8e96-8b5d276d329a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---------.parameters() 方法-------------------\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([10, 5])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([10])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([1, 10])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([1])\n",
            "---------.named_parameters() 方法-------------\n",
            "<class 'torch.nn.parameter.Parameter'> model.0.weight torch.Size([10, 5])\n",
            "<class 'torch.nn.parameter.Parameter'> model.0.bias torch.Size([10])\n",
            "<class 'torch.nn.parameter.Parameter'> model.2.weight torch.Size([1, 10])\n",
            "<class 'torch.nn.parameter.Parameter'> model.2.bias torch.Size([1])\n",
            "---------.state_dict() 方法-------------------\n",
            "<class 'torch.Tensor'> model.0.weight torch.Size([10, 5])\n",
            "<class 'torch.Tensor'> model.0.bias torch.Size([10])\n",
            "<class 'torch.Tensor'> model.2.weight torch.Size([1, 10])\n",
            "<class 'torch.Tensor'> model.2.bias torch.Size([1])\n",
            "---------.modules() 方法----------------------\n",
            "<class '__main__.BPNNModeler'> BPNNModeler(\n",
            "  (model): Sequential(\n",
            "    (0): Linear(in_features=5, out_features=10, bias=True)\n",
            "    (1): Sigmoid()\n",
            "    (2): Linear(in_features=10, out_features=1, bias=True)\n",
            "    (3): Sigmoid()\n",
            "    (4): Flatten(start_dim=0, end_dim=-1)\n",
            "  )\n",
            ")\n",
            "<class 'torch.nn.modules.container.Sequential'> Sequential(\n",
            "  (0): Linear(in_features=5, out_features=10, bias=True)\n",
            "  (1): Sigmoid()\n",
            "  (2): Linear(in_features=10, out_features=1, bias=True)\n",
            "  (3): Sigmoid()\n",
            "  (4): Flatten(start_dim=0, end_dim=-1)\n",
            ")\n",
            "<class 'torch.nn.modules.linear.Linear'> Linear(in_features=5, out_features=10, bias=True)\n",
            "<class 'torch.nn.modules.activation.Sigmoid'> Sigmoid()\n",
            "<class 'torch.nn.modules.linear.Linear'> Linear(in_features=10, out_features=1, bias=True)\n",
            "<class 'torch.nn.modules.activation.Sigmoid'> Sigmoid()\n",
            "<class 'torch.nn.modules.flatten.Flatten'> Flatten(start_dim=0, end_dim=-1)\n",
            "---------.named_modules() 方法----------------\n",
            "<class '__main__.BPNNModeler'>  BPNNModeler(\n",
            "  (model): Sequential(\n",
            "    (0): Linear(in_features=5, out_features=10, bias=True)\n",
            "    (1): Sigmoid()\n",
            "    (2): Linear(in_features=10, out_features=1, bias=True)\n",
            "    (3): Sigmoid()\n",
            "    (4): Flatten(start_dim=0, end_dim=-1)\n",
            "  )\n",
            ")\n",
            "<class 'torch.nn.modules.container.Sequential'> model Sequential(\n",
            "  (0): Linear(in_features=5, out_features=10, bias=True)\n",
            "  (1): Sigmoid()\n",
            "  (2): Linear(in_features=10, out_features=1, bias=True)\n",
            "  (3): Sigmoid()\n",
            "  (4): Flatten(start_dim=0, end_dim=-1)\n",
            ")\n",
            "<class 'torch.nn.modules.linear.Linear'> model.0 Linear(in_features=5, out_features=10, bias=True)\n",
            "<class 'torch.nn.modules.activation.Sigmoid'> model.1 Sigmoid()\n",
            "<class 'torch.nn.modules.linear.Linear'> model.2 Linear(in_features=10, out_features=1, bias=True)\n",
            "<class 'torch.nn.modules.activation.Sigmoid'> model.3 Sigmoid()\n",
            "<class 'torch.nn.modules.flatten.Flatten'> model.4 Flatten(start_dim=0, end_dim=-1)\n",
            "---------.named_children() 方法----------------\n",
            "<class 'torch.nn.modules.container.Sequential'> model Sequential(\n",
            "  (0): Linear(in_features=5, out_features=10, bias=True)\n",
            "  (1): Sigmoid()\n",
            "  (2): Linear(in_features=10, out_features=1, bias=True)\n",
            "  (3): Sigmoid()\n",
            "  (4): Flatten(start_dim=0, end_dim=-1)\n",
            ")\n",
            "---------.parameters() 方法-------------------\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([10, 5])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([10])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([1, 10])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([1])\n",
            "---------.named_parameters() 方法-------------\n",
            "<class 'torch.nn.parameter.Parameter'> layer1_linear.weight torch.Size([10, 5])\n",
            "<class 'torch.nn.parameter.Parameter'> layer1_linear.bias torch.Size([10])\n",
            "<class 'torch.nn.parameter.Parameter'> layer2_linear.weight torch.Size([1, 10])\n",
            "<class 'torch.nn.parameter.Parameter'> layer2_linear.bias torch.Size([1])\n",
            "---------.state_dict() 方法-------------------\n",
            "<class 'torch.Tensor'> layer1_linear.weight torch.Size([10, 5])\n",
            "<class 'torch.Tensor'> layer1_linear.bias torch.Size([10])\n",
            "<class 'torch.Tensor'> layer2_linear.weight torch.Size([1, 10])\n",
            "<class 'torch.Tensor'> layer2_linear.bias torch.Size([1])\n",
            "---------.modules() 方法----------------------\n",
            "<class '__main__.BPNNModeler2'> BPNNModeler2(\n",
            "  (layer1_linear): Linear(in_features=5, out_features=10, bias=True)\n",
            "  (layer1_sigmoid): Sigmoid()\n",
            "  (layer2_linear): Linear(in_features=10, out_features=1, bias=True)\n",
            "  (layer2_sigmoid): Sigmoid()\n",
            "  (layer2_flattern): Flatten(start_dim=0, end_dim=-1)\n",
            ")\n",
            "<class 'torch.nn.modules.linear.Linear'> Linear(in_features=5, out_features=10, bias=True)\n",
            "<class 'torch.nn.modules.activation.Sigmoid'> Sigmoid()\n",
            "<class 'torch.nn.modules.linear.Linear'> Linear(in_features=10, out_features=1, bias=True)\n",
            "<class 'torch.nn.modules.activation.Sigmoid'> Sigmoid()\n",
            "<class 'torch.nn.modules.flatten.Flatten'> Flatten(start_dim=0, end_dim=-1)\n",
            "---------.named_modules() 方法----------------\n",
            "<class '__main__.BPNNModeler2'>  BPNNModeler2(\n",
            "  (layer1_linear): Linear(in_features=5, out_features=10, bias=True)\n",
            "  (layer1_sigmoid): Sigmoid()\n",
            "  (layer2_linear): Linear(in_features=10, out_features=1, bias=True)\n",
            "  (layer2_sigmoid): Sigmoid()\n",
            "  (layer2_flattern): Flatten(start_dim=0, end_dim=-1)\n",
            ")\n",
            "<class 'torch.nn.modules.linear.Linear'> layer1_linear Linear(in_features=5, out_features=10, bias=True)\n",
            "<class 'torch.nn.modules.activation.Sigmoid'> layer1_sigmoid Sigmoid()\n",
            "<class 'torch.nn.modules.linear.Linear'> layer2_linear Linear(in_features=10, out_features=1, bias=True)\n",
            "<class 'torch.nn.modules.activation.Sigmoid'> layer2_sigmoid Sigmoid()\n",
            "<class 'torch.nn.modules.flatten.Flatten'> layer2_flattern Flatten(start_dim=0, end_dim=-1)\n",
            "---------.named_children() 方法----------------\n",
            "<class 'torch.nn.modules.linear.Linear'> layer1_linear Linear(in_features=5, out_features=10, bias=True)\n",
            "<class 'torch.nn.modules.activation.Sigmoid'> layer1_sigmoid Sigmoid()\n",
            "<class 'torch.nn.modules.linear.Linear'> layer2_linear Linear(in_features=10, out_features=1, bias=True)\n",
            "<class 'torch.nn.modules.activation.Sigmoid'> layer2_sigmoid Sigmoid()\n",
            "<class 'torch.nn.modules.flatten.Flatten'> layer2_flattern Flatten(start_dim=0, end_dim=-1)\n",
            "---------.parameters() 方法-------------------\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([10, 5])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([10])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([1, 10])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([1])\n",
            "---------.named_parameters() 方法-------------\n",
            "<class 'torch.nn.parameter.Parameter'> layer1_linear.weight torch.Size([10, 5])\n",
            "<class 'torch.nn.parameter.Parameter'> layer1_linear.bias torch.Size([10])\n",
            "<class 'torch.nn.parameter.Parameter'> layer2_linear.weight torch.Size([1, 10])\n",
            "<class 'torch.nn.parameter.Parameter'> layer2_linear.bias torch.Size([1])\n",
            "---------.state_dict() 方法-------------------\n",
            "<class 'torch.Tensor'> layer1_linear.weight torch.Size([10, 5])\n",
            "<class 'torch.Tensor'> layer1_linear.bias torch.Size([10])\n",
            "<class 'torch.Tensor'> layer2_linear.weight torch.Size([1, 10])\n",
            "<class 'torch.Tensor'> layer2_linear.bias torch.Size([1])\n",
            "---------.modules() 方法----------------------\n",
            "<class '__main__.BPNNModeler3'> BPNNModeler3(\n",
            "  (layer1_linear): Linear(in_features=5, out_features=10, bias=True)\n",
            "  (layer2_linear): Linear(in_features=10, out_features=1, bias=True)\n",
            ")\n",
            "<class 'torch.nn.modules.linear.Linear'> Linear(in_features=5, out_features=10, bias=True)\n",
            "<class 'torch.nn.modules.linear.Linear'> Linear(in_features=10, out_features=1, bias=True)\n",
            "---------.named_modules() 方法----------------\n",
            "<class '__main__.BPNNModeler3'>  BPNNModeler3(\n",
            "  (layer1_linear): Linear(in_features=5, out_features=10, bias=True)\n",
            "  (layer2_linear): Linear(in_features=10, out_features=1, bias=True)\n",
            ")\n",
            "<class 'torch.nn.modules.linear.Linear'> layer1_linear Linear(in_features=5, out_features=10, bias=True)\n",
            "<class 'torch.nn.modules.linear.Linear'> layer2_linear Linear(in_features=10, out_features=1, bias=True)\n",
            "---------.named_children() 方法----------------\n",
            "<class 'torch.nn.modules.linear.Linear'> layer1_linear Linear(in_features=5, out_features=10, bias=True)\n",
            "<class 'torch.nn.modules.linear.Linear'> layer2_linear Linear(in_features=10, out_features=1, bias=True)\n",
            "---------.parameters() 方法-------------------\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([5, 10])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([10])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([10, 1])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([10])\n",
            "---------.named_parameters() 方法-------------\n",
            "<class 'torch.nn.parameter.Parameter'> w1 torch.Size([5, 10])\n",
            "<class 'torch.nn.parameter.Parameter'> b1 torch.Size([10])\n",
            "<class 'torch.nn.parameter.Parameter'> w2 torch.Size([10, 1])\n",
            "<class 'torch.nn.parameter.Parameter'> b2 torch.Size([10])\n",
            "---------.state_dict() 方法-------------------\n",
            "<class 'torch.Tensor'> w1 torch.Size([5, 10])\n",
            "<class 'torch.Tensor'> b1 torch.Size([10])\n",
            "<class 'torch.Tensor'> w2 torch.Size([10, 1])\n",
            "<class 'torch.Tensor'> b2 torch.Size([10])\n",
            "---------.modules() 方法----------------------\n",
            "<class '__main__.BPNNModeler4'> BPNNModeler4()\n",
            "---------.named_modules() 方法----------------\n",
            "<class '__main__.BPNNModeler4'>  BPNNModeler4()\n",
            "---------.named_children() 方法----------------\n"
          ]
        }
      ]
    }
  ]
}